{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "2.2.4\n",
      "No GPU found\n",
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, time, random\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, Flatten, TimeDistributed, Bidirectional\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM, Dropout, Activation, Permute\n",
    "from keras import regularizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import backend as K\n",
    "#from keras.backend import permute_dimensions\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "    \n",
    "with tf.device('/cpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras_handler.SequenceGenerator import SequenceGenerator\n",
    "# sg = SequenceGenerator(PredictIntent.data_path, PredictIntent.intent_index, PredictIntent.max_sequence_length, 0.2)\n",
    "# generator = sg.generate_batch(5, subset='training')\n",
    "# tuple1 = next(generator)\n",
    "# print(tuple1[0].shape)\n",
    "# print(tuple1[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_handler.predict_intent import PredictIntent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_intents 26\n"
     ]
    }
   ],
   "source": [
    "pi = PredictIntent(is_general = False)\n",
    "pi.batch_size = 13\n",
    "pi.max_sequence_length = 5\n",
    "pi.intent_embedding_dim = 10\n",
    "pi.num_units = 30\n",
    "pi.validation_split = 0.2\n",
    "pi.random_state = 42\n",
    "pi.data_path = \"../../sandbox/feature_and_vector_seq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/demidovs/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/demidovs/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/demidovs/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "471/809 [================>.............] - ETA: 8s - loss: 2.6378 - acc: 0.2141"
     ]
    }
   ],
   "source": [
    "pi.build_BiRNN_model()\n",
    "history_BiRNN = pi.fit_generator(epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape (?, 4, 26)\n",
      "Epoch 1/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 2.8342 - acc: 0.1876 - val_loss: 2.7032 - val_acc: 0.20990s - loss: 2.8352 - acc: 0.187\n",
      "Epoch 2/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.6631 - acc: 0.2238 - val_loss: 2.6923 - val_acc: 0.2089\n",
      "Epoch 3/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.6324 - acc: 0.2373 - val_loss: 2.6855 - val_acc: 0.2079\n",
      "Epoch 4/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.6363 - acc: 0.2350 - val_loss: 2.6504 - val_acc: 0.2247\n",
      "Epoch 5/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.6166 - acc: 0.2440 - val_loss: 2.6300 - val_acc: 0.2355\n",
      "Epoch 6/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.6100 - acc: 0.2480 - val_loss: 2.6212 - val_acc: 0.2386\n",
      "Epoch 7/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.5750 - acc: 0.2566 - val_loss: 2.6453 - val_acc: 0.2259\n",
      "Epoch 8/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.5959 - acc: 0.2486 - val_loss: 2.6246 - val_acc: 0.2377A: 1s - loss: 2.591 - ETA: 0s - loss: 2.5946 - acc: \n",
      "Epoch 9/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.5903 - acc: 0.2550 - val_loss: 2.6148 - val_acc: 0.2373\n",
      "Epoch 10/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.5622 - acc: 0.2608 - val_loss: 2.5991 - val_acc: 0.2486\n",
      "Epoch 11/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.5821 - acc: 0.2571 - val_loss: 2.5625 - val_acc: 0.2553\n",
      "Epoch 12/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.5690 - acc: 0.2589 - val_loss: 2.5722 - val_acc: 0.2539\n",
      "Epoch 13/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.5499 - acc: 0.2656 - val_loss: 2.5522 - val_acc: 0.2537\n",
      "Epoch 14/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.5438 - acc: 0.2701 - val_loss: 2.5530 - val_acc: 0.2605\n",
      "Epoch 15/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.5380 - acc: 0.2693 - val_loss: 2.5721 - val_acc: 0.2583\n",
      "Epoch 16/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.5315 - acc: 0.2739 - val_loss: 2.5268 - val_acc: 0.2692\n",
      "Epoch 17/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.5191 - acc: 0.2792 - val_loss: 2.5182 - val_acc: 0.2707\n",
      "Epoch 18/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.5351 - acc: 0.2733 - val_loss: 2.5148 - val_acc: 0.2824\n",
      "Epoch 19/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.4979 - acc: 0.2879 - val_loss: 2.5110 - val_acc: 0.2762\n",
      "Epoch 20/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.4988 - acc: 0.2881 - val_loss: 2.4992 - val_acc: 0.2849\n",
      "Epoch 21/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.4864 - acc: 0.2920 - val_loss: 2.4700 - val_acc: 0.2984\n",
      "Epoch 22/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.4908 - acc: 0.2919 - val_loss: 2.4917 - val_acc: 0.2878\n",
      "Epoch 23/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.4818 - acc: 0.2961 - val_loss: 2.4915 - val_acc: 0.2876\n",
      "Epoch 24/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.4766 - acc: 0.2932 - val_loss: 2.4444 - val_acc: 0.3006\n",
      "Epoch 25/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.4675 - acc: 0.2974 - val_loss: 2.4383 - val_acc: 0.3141\n",
      "Epoch 26/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.4640 - acc: 0.3014 - val_loss: 2.4357 - val_acc: 0.3055c\n",
      "Epoch 27/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.4602 - acc: 0.3033 - val_loss: 2.4656 - val_acc: 0.2921\n",
      "Epoch 28/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.4544 - acc: 0.3015 - val_loss: 2.4047 - val_acc: 0.3157\n",
      "Epoch 29/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.4382 - acc: 0.3075 - val_loss: 2.4245 - val_acc: 0.3099\n",
      "Epoch 30/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.4470 - acc: 0.3073 - val_loss: 2.4287 - val_acc: 0.3119\n",
      "Epoch 31/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.4472 - acc: 0.3059 - val_loss: 2.3888 - val_acc: 0.3298\n",
      "Epoch 32/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.4183 - acc: 0.3151 - val_loss: 2.4104 - val_acc: 0.3141\n",
      "Epoch 33/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.4339 - acc: 0.3123 - val_loss: 2.3690 - val_acc: 0.3369\n",
      "Epoch 34/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.4027 - acc: 0.3232 - val_loss: 2.4109 - val_acc: 0.3222\n",
      "Epoch 35/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.4222 - acc: 0.3177 - val_loss: 2.3451 - val_acc: 0.3375\n",
      "Epoch 36/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.4087 - acc: 0.3213 - val_loss: 2.3506 - val_acc: 0.3385\n",
      "Epoch 37/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.4011 - acc: 0.3231 - val_loss: 2.3498 - val_acc: 0.3419\n",
      "Epoch 38/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.4046 - acc: 0.3243 - val_loss: 2.3507 - val_acc: 0.3497\n",
      "Epoch 39/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.3895 - acc: 0.3267 - val_loss: 2.3609 - val_acc: 0.3391\n",
      "Epoch 40/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.3836 - acc: 0.3320 - val_loss: 2.3275 - val_acc: 0.3566\n",
      "Epoch 41/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.4060 - acc: 0.3252 - val_loss: 2.3025 - val_acc: 0.3587\n",
      "Epoch 42/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.3805 - acc: 0.3321 - val_loss: 2.3390 - val_acc: 0.3462\n",
      "Epoch 43/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.3779 - acc: 0.3335 - val_loss: 2.3286 - val_acc: 0.3483\n",
      "Epoch 44/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.3716 - acc: 0.3365 - val_loss: 2.3079 - val_acc: 0.3641\n",
      "Epoch 45/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.3720 - acc: 0.3349 - val_loss: 2.3097 - val_acc: 0.3534\n",
      "Epoch 46/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.3624 - acc: 0.3402 - val_loss: 2.2853 - val_acc: 0.3668ss: 2.3550  - ETA:\n",
      "Epoch 47/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.3607 - acc: 0.3377 - val_loss: 2.3025 - val_acc: 0.3659\n",
      "Epoch 48/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.3482 - acc: 0.3430 - val_loss: 2.2808 - val_acc: 0.3693\n",
      "Epoch 49/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.3552 - acc: 0.3440 - val_loss: 2.2802 - val_acc: 0.3665\n",
      "Epoch 50/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.3605 - acc: 0.3401 - val_loss: 2.3145 - val_acc: 0.3543\n",
      "Epoch 51/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.3685 - acc: 0.3382 - val_loss: 2.2815 - val_acc: 0.3689\n",
      "Epoch 52/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.3392 - acc: 0.3484 - val_loss: 2.2695 - val_acc: 0.3728\n",
      "Epoch 53/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.3387 - acc: 0.3460 - val_loss: 2.2712 - val_acc: 0.3778\n",
      "Epoch 54/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.3349 - acc: 0.3495 - val_loss: 2.2523 - val_acc: 0.3784\n",
      "Epoch 55/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.3299 - acc: 0.3524 - val_loss: 2.2520 - val_acc: 0.3763\n",
      "Epoch 56/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.3316 - acc: 0.3473 - val_loss: 2.2836 - val_acc: 0.3729\n",
      "Epoch 57/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.3204 - acc: 0.3512 - val_loss: 2.2214 - val_acc: 0.3877\n",
      "Epoch 58/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.3390 - acc: 0.3471 - val_loss: 2.2535 - val_acc: 0.3771\n",
      "Epoch 59/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.3092 - acc: 0.3574 - val_loss: 2.2340 - val_acc: 0.3832\n",
      "Epoch 60/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.3368 - acc: 0.3490 - val_loss: 2.2780 - val_acc: 0.3699\n",
      "Epoch 61/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.3279 - acc: 0.3505 - val_loss: 2.2160 - val_acc: 0.3906\n",
      "Epoch 62/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.3251 - acc: 0.3502 - val_loss: 2.2042 - val_acc: 0.3928\n",
      "Epoch 63/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.3180 - acc: 0.3571 - val_loss: 2.2418 - val_acc: 0.3866\n",
      "Epoch 64/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.3145 - acc: 0.3540 - val_loss: 2.2262 - val_acc: 0.3859\n",
      "Epoch 65/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.2945 - acc: 0.3620 - val_loss: 2.2110 - val_acc: 0.3968\n",
      "Epoch 66/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.3071 - acc: 0.3557 - val_loss: 2.2303 - val_acc: 0.3887\n",
      "Epoch 67/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.3168 - acc: 0.3551 - val_loss: 2.1883 - val_acc: 0.3988\n",
      "Epoch 68/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.2966 - acc: 0.3617 - val_loss: 2.2333 - val_acc: 0.3853\n",
      "Epoch 69/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.3123 - acc: 0.3598 - val_loss: 2.2431 - val_acc: 0.3824\n",
      "Epoch 70/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.2976 - acc: 0.3629 - val_loss: 2.1893 - val_acc: 0.3983\n",
      "Epoch 71/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.3042 - acc: 0.3598 - val_loss: 2.2109 - val_acc: 0.3937\n",
      "Epoch 72/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.2963 - acc: 0.3592 - val_loss: 2.2352 - val_acc: 0.3857\n",
      "Epoch 73/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.2930 - acc: 0.3635 - val_loss: 2.2242 - val_acc: 0.3931\n",
      "Epoch 74/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.2907 - acc: 0.3644 - val_loss: 2.1774 - val_acc: 0.4040\n",
      "Epoch 75/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.3086 - acc: 0.3563 - val_loss: 2.1924 - val_acc: 0.4008\n",
      "Epoch 76/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.2880 - acc: 0.3637 - val_loss: 2.2006 - val_acc: 0.3944\n",
      "Epoch 77/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.2929 - acc: 0.3638 - val_loss: 2.1730 - val_acc: 0.4059\n",
      "Epoch 78/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.2891 - acc: 0.3657 - val_loss: 2.2315 - val_acc: 0.3868s - loss: 2.2888 - \n",
      "Epoch 79/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.2822 - acc: 0.3648 - val_loss: 2.1506 - val_acc: 0.4126\n",
      "Epoch 80/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.2851 - acc: 0.3626 - val_loss: 2.1934 - val_acc: 0.3984\n",
      "Epoch 81/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.2831 - acc: 0.3692 - val_loss: 2.1597 - val_acc: 0.4080\n",
      "Epoch 82/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.2737 - acc: 0.3667 - val_loss: 2.2328 - val_acc: 0.3863- loss: 2.2756\n",
      "Epoch 83/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.2934 - acc: 0.3610 - val_loss: 2.1308 - val_acc: 0.4184\n",
      "Epoch 84/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.2702 - acc: 0.3714 - val_loss: 2.2174 - val_acc: 0.3871\n",
      "Epoch 85/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.2600 - acc: 0.3729 - val_loss: 2.1613 - val_acc: 0.4049\n",
      "Epoch 86/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.2848 - acc: 0.3662 - val_loss: 2.1847 - val_acc: 0.4010\n",
      "Epoch 87/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.2738 - acc: 0.3704 - val_loss: 2.1446 - val_acc: 0.4201\n",
      "Epoch 88/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.2666 - acc: 0.3703 - val_loss: 2.1988 - val_acc: 0.3905\n",
      "Epoch 89/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.2801 - acc: 0.3696 - val_loss: 2.1778 - val_acc: 0.4063\n",
      "Epoch 90/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.2724 - acc: 0.3690 - val_loss: 2.1619 - val_acc: 0.4061\n",
      "Epoch 91/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.2595 - acc: 0.3746 - val_loss: 2.1746 - val_acc: 0.4016\n",
      "Epoch 92/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.2636 - acc: 0.3702 - val_loss: 2.1442 - val_acc: 0.4086\n",
      "Epoch 93/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.2807 - acc: 0.3674 - val_loss: 2.1915 - val_acc: 0.3995\n",
      "Epoch 94/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.2544 - acc: 0.3755 - val_loss: 2.1574 - val_acc: 0.4127\n",
      "Epoch 95/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.2704 - acc: 0.3703 - val_loss: 2.1447 - val_acc: 0.4071\n",
      "Epoch 96/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.2747 - acc: 0.3724 - val_loss: 2.1722 - val_acc: 0.4061\n",
      "Epoch 97/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.2334 - acc: 0.3820 - val_loss: 2.1443 - val_acc: 0.4164ETA: 0s - loss: 2.2364 \n",
      "Epoch 98/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 2.2729 - acc: 0.3705 - val_loss: 2.1950 - val_acc: 0.3951\n",
      "Epoch 99/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.2631 - acc: 0.3711 - val_loss: 2.1396 - val_acc: 0.4174\n",
      "Epoch 100/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 2.2467 - acc: 0.3787 - val_loss: 2.1595 - val_acc: 0.4087\n"
     ]
    }
   ],
   "source": [
    "pi.build_RNN_model()\n",
    "history_RNN = pi.fit_generator(epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.9454 - acc: 0.1158 - val_loss: 2.8787 - val_acc: 0.1494\n",
      "Epoch 2/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.8221 - acc: 0.1641 - val_loss: 2.7482 - val_acc: 0.1898\n",
      "Epoch 3/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.7107 - acc: 0.2095 - val_loss: 2.6090 - val_acc: 0.2607\n",
      "Epoch 4/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.5529 - acc: 0.2793 - val_loss: 2.4454 - val_acc: 0.3057- loss\n",
      "Epoch 5/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 2.3838 - acc: 0.3261 - val_loss: 2.3137 - val_acc: 0.3464\n",
      "Epoch 6/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.2829 - acc: 0.3662 - val_loss: 2.1802 - val_acc: 0.4049\n",
      "Epoch 7/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.1948 - acc: 0.4035 - val_loss: 2.1948 - val_acc: 0.4103\n",
      "Epoch 8/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.1127 - acc: 0.4247 - val_loss: 2.0280 - val_acc: 0.4704\n",
      "Epoch 9/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.0579 - acc: 0.4456 - val_loss: 2.0324 - val_acc: 0.4761\n",
      "Epoch 10/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.0001 - acc: 0.4653 - val_loss: 1.9668 - val_acc: 0.4872\n",
      "Epoch 11/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.9179 - acc: 0.4922 - val_loss: 2.0735 - val_acc: 0.4779\n",
      "Epoch 12/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.9205 - acc: 0.4845 - val_loss: 1.9186 - val_acc: 0.5082\n",
      "Epoch 13/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.8943 - acc: 0.4951 - val_loss: 1.9325 - val_acc: 0.4872\n",
      "Epoch 14/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.8701 - acc: 0.5048 - val_loss: 1.9156 - val_acc: 0.5095\n",
      "Epoch 15/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.8882 - acc: 0.4962 - val_loss: 2.0185 - val_acc: 0.4974\n",
      "Epoch 16/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.8201 - acc: 0.5119 - val_loss: 1.9592 - val_acc: 0.5130\n",
      "Epoch 17/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.8458 - acc: 0.5099 - val_loss: 1.9138 - val_acc: 0.5143\n",
      "Epoch 18/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 1.8654 - acc: 0.4993 - val_loss: 1.9377 - val_acc: 0.5102\n",
      "Epoch 19/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.8790 - acc: 0.5041 - val_loss: 1.8957 - val_acc: 0.5038\n",
      "Epoch 20/100\n",
      "809/809 [==============================] - 21s 25ms/step - loss: 1.7915 - acc: 0.5186 - val_loss: 1.9289 - val_acc: 0.5418\n",
      "Epoch 21/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.8901 - acc: 0.4989 - val_loss: 1.9524 - val_acc: 0.5079a\n",
      "Epoch 22/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.8672 - acc: 0.5058 - val_loss: 2.1073 - val_acc: 0.4973\n",
      "Epoch 23/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.9294 - acc: 0.4842 - val_loss: 1.9757 - val_acc: 0.5213 - los\n",
      "Epoch 24/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.8424 - acc: 0.5193 - val_loss: 2.0673 - val_acc: 0.4902\n",
      "Epoch 25/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.9022 - acc: 0.5020 - val_loss: 1.9800 - val_acc: 0.4922\n",
      "Epoch 26/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.9487 - acc: 0.4839 - val_loss: 2.0245 - val_acc: 0.5081\n",
      "Epoch 27/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.9141 - acc: 0.4920 - val_loss: 2.0493 - val_acc: 0.4688\n",
      "Epoch 28/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.9334 - acc: 0.4867 - val_loss: 2.1714 - val_acc: 0.5019\n",
      "Epoch 29/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.9249 - acc: 0.4900 - val_loss: 1.9836 - val_acc: 0.5092\n",
      "Epoch 30/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.9544 - acc: 0.4843 - val_loss: 2.0402 - val_acc: 0.4788\n",
      "Epoch 31/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.9528 - acc: 0.4813 - val_loss: 2.0282 - val_acc: 0.4806\n",
      "Epoch 32/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.9813 - acc: 0.4766 - val_loss: 2.3197 - val_acc: 0.4965\n",
      "Epoch 33/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.9063 - acc: 0.4908 - val_loss: 1.9977 - val_acc: 0.4742\n",
      "Epoch 34/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.9890 - acc: 0.4709 - val_loss: 2.0914 - val_acc: 0.4625\n",
      "Epoch 35/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.9560 - acc: 0.4844 - val_loss: 2.0411 - val_acc: 0.4555\n",
      "Epoch 36/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.0160 - acc: 0.4718 - val_loss: 2.0856 - val_acc: 0.4903\n",
      "Epoch 37/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 2.0277 - acc: 0.4701 - val_loss: 2.1539 - val_acc: 0.4809\n",
      "Epoch 38/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.9727 - acc: 0.4882 - val_loss: 2.1902 - val_acc: 0.4552\n",
      "Epoch 39/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 2.0452 - acc: 0.4614 - val_loss: 2.1439 - val_acc: 0.4779\n",
      "Epoch 40/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.9841 - acc: 0.4784 - val_loss: 2.2428 - val_acc: 0.4536\n",
      "Epoch 41/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.0721 - acc: 0.4580 - val_loss: 2.1286 - val_acc: 0.4850\n",
      "Epoch 42/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.0025 - acc: 0.4803 - val_loss: 2.1884 - val_acc: 0.4321\n",
      "Epoch 43/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.0800 - acc: 0.4597 - val_loss: 2.1785 - val_acc: 0.4629\n",
      "Epoch 44/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.0488 - acc: 0.4542 - val_loss: 2.2775 - val_acc: 0.4203\n",
      "Epoch 45/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.0550 - acc: 0.4624 - val_loss: 2.2599 - val_acc: 0.4576\n",
      "Epoch 46/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.0256 - acc: 0.4663 - val_loss: 2.2800 - val_acc: 0.4663\n",
      "Epoch 47/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.0740 - acc: 0.4595 - val_loss: 2.1906 - val_acc: 0.4763\n",
      "Epoch 48/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.0855 - acc: 0.4486 - val_loss: 2.1789 - val_acc: 0.4688\n",
      "Epoch 49/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.0895 - acc: 0.4570 - val_loss: 2.2425 - val_acc: 0.4732\n",
      "Epoch 50/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.0790 - acc: 0.4468 - val_loss: 2.0641 - val_acc: 0.4551\n",
      "Epoch 51/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.1053 - acc: 0.4540 - val_loss: 2.5135 - val_acc: 0.4703\n",
      "Epoch 52/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.0966 - acc: 0.4566 - val_loss: 2.4011 - val_acc: 0.4274\n",
      "Epoch 53/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.0878 - acc: 0.4512 - val_loss: 2.1816 - val_acc: 0.4569\n",
      "Epoch 54/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.1162 - acc: 0.4500 - val_loss: 2.2437 - val_acc: 0.4786\n",
      "Epoch 55/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.1027 - acc: 0.4478 - val_loss: 2.4042 - val_acc: 0.4547\n",
      "Epoch 56/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.1660 - acc: 0.4462 - val_loss: 2.3654 - val_acc: 0.4469\n",
      "Epoch 57/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.1232 - acc: 0.4463 - val_loss: 2.3008 - val_acc: 0.4608 4s - loss: 2.1308  - ETA:  - ETA: 1s - loss: 2.12 - ETA: 0s - loss: 2.1306 - acc: 0.44 - ETA: 0s - loss: 2.1332 - \n",
      "Epoch 58/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.1365 - acc: 0.4422 - val_loss: 2.1733 - val_acc: 0.4765\n",
      "Epoch 59/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 2.1796 - acc: 0.4260 - val_loss: 2.2728 - val_acc: 0.4141\n",
      "Epoch 60/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.0985 - acc: 0.4566 - val_loss: 2.4669 - val_acc: 0.4452\n",
      "Epoch 61/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.1767 - acc: 0.4317 - val_loss: 2.2903 - val_acc: 0.4518\n",
      "Epoch 62/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 2.1823 - acc: 0.4293 - val_loss: 2.4547 - val_acc: 0.4046\n",
      "Epoch 63/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.1813 - acc: 0.4255 - val_loss: 2.2851 - val_acc: 0.4466\n",
      "Epoch 64/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.1635 - acc: 0.4304 - val_loss: 2.4567 - val_acc: 0.4274\n",
      "Epoch 65/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.1718 - acc: 0.4325 - val_loss: 2.3425 - val_acc: 0.4206\n",
      "Epoch 66/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.1881 - acc: 0.4255 - val_loss: 2.4537 - val_acc: 0.4523 l\n",
      "Epoch 67/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.2048 - acc: 0.4202 - val_loss: 2.2494 - val_acc: 0.4538\n",
      "Epoch 68/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 2.2396 - acc: 0.4215 - val_loss: 2.3942 - val_acc: 0.4062\n",
      "Epoch 69/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.2093 - acc: 0.4231 - val_loss: 2.2510 - val_acc: 0.4702\n",
      "Epoch 70/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.2270 - acc: 0.4233 - val_loss: 2.4215 - val_acc: 0.4262- loss: 2.2054  -\n",
      "Epoch 71/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.2519 - acc: 0.4133 - val_loss: 2.3820 - val_acc: 0.4369\n",
      "Epoch 72/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.2117 - acc: 0.4215 - val_loss: 2.2674 - val_acc: 0.4523\n",
      "Epoch 73/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.2711 - acc: 0.4075 - val_loss: 2.3145 - val_acc: 0.4533\n",
      "Epoch 74/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.2708 - acc: 0.4106 - val_loss: 2.3977 - val_acc: 0.4114\n",
      "Epoch 75/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.2516 - acc: 0.4062 - val_loss: 2.4396 - val_acc: 0.4320\n",
      "Epoch 76/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.2976 - acc: 0.4137 - val_loss: 2.4902 - val_acc: 0.3836\n",
      "Epoch 77/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 2.2777 - acc: 0.4124 - val_loss: 2.6879 - val_acc: 0.4036\n",
      "Epoch 78/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.3055 - acc: 0.3991 - val_loss: 2.3710 - val_acc: 0.3782\n",
      "Epoch 79/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.2937 - acc: 0.4025 - val_loss: 2.4277 - val_acc: 0.4004\n",
      "Epoch 80/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.2960 - acc: 0.4042 - val_loss: 2.4025 - val_acc: 0.4087\n",
      "Epoch 81/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.3111 - acc: 0.3990 - val_loss: 2.3593 - val_acc: 0.3884\n",
      "Epoch 82/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.3508 - acc: 0.3940 - val_loss: 2.4976 - val_acc: 0.3937\n",
      "Epoch 83/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.3460 - acc: 0.3916 - val_loss: 2.5116 - val_acc: 0.4091\n",
      "Epoch 84/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.2946 - acc: 0.4021 - val_loss: 2.5442 - val_acc: 0.3711\n",
      "Epoch 85/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.3549 - acc: 0.3982 - val_loss: 2.7820 - val_acc: 0.3844\n",
      "Epoch 86/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.3474 - acc: 0.3894 - val_loss: 2.2917 - val_acc: 0.4133\n",
      "Epoch 87/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.3238 - acc: 0.4011 - val_loss: 2.3955 - val_acc: 0.3780\n",
      "Epoch 88/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.4137 - acc: 0.3766 - val_loss: 2.4356 - val_acc: 0.3731\n",
      "Epoch 89/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.3191 - acc: 0.3977 - val_loss: 2.3779 - val_acc: 0.3618\n",
      "Epoch 90/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.3884 - acc: 0.3782 - val_loss: 2.4054 - val_acc: 0.3874\n",
      "Epoch 91/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.3426 - acc: 0.3843 - val_loss: 2.3008 - val_acc: 0.4219\n",
      "Epoch 92/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.4073 - acc: 0.3690 - val_loss: 2.5593 - val_acc: 0.3792\n",
      "Epoch 93/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.4132 - acc: 0.3700 - val_loss: 2.3789 - val_acc: 0.4119\n",
      "Epoch 94/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.3582 - acc: 0.3927 - val_loss: 2.4498 - val_acc: 0.4154\n",
      "Epoch 95/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.3410 - acc: 0.3897 - val_loss: 2.5212 - val_acc: 0.3869\n",
      "Epoch 96/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.4958 - acc: 0.3484 - val_loss: 2.4900 - val_acc: 0.3179\n",
      "Epoch 97/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.4287 - acc: 0.3729 - val_loss: 2.3431 - val_acc: 0.3937\n",
      "Epoch 98/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.4103 - acc: 0.3709 - val_loss: 2.4920 - val_acc: 0.4316\n",
      "Epoch 99/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.3820 - acc: 0.3881 - val_loss: 2.4344 - val_acc: 0.4102\n",
      "Epoch 100/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.4429 - acc: 0.3630 - val_loss: 2.4876 - val_acc: 0.3632\n"
     ]
    }
   ],
   "source": [
    "pi.build_CNN_model()\n",
    "history_CNN = pi.fit_generator(epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.9887 - acc: 0.1136 - val_loss: 2.8725 - val_acc: 0.1462\n",
      "Epoch 2/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 2.8533 - acc: 0.1610 - val_loss: 2.8205 - val_acc: 0.1790\n",
      "Epoch 3/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.8038 - acc: 0.1863 - val_loss: 2.7608 - val_acc: 0.1927\n",
      "Epoch 4/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.7642 - acc: 0.2083 - val_loss: 2.7465 - val_acc: 0.2206\n",
      "Epoch 5/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.7098 - acc: 0.2398 - val_loss: 2.6791 - val_acc: 0.2492\n",
      "Epoch 6/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.6769 - acc: 0.2640 - val_loss: 2.6609 - val_acc: 0.2806\n",
      "Epoch 7/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.6231 - acc: 0.2924 - val_loss: 2.5886 - val_acc: 0.3142\n",
      "Epoch 8/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.5990 - acc: 0.3087 - val_loss: 2.6060 - val_acc: 0.3135\n",
      "Epoch 9/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.5832 - acc: 0.3226 - val_loss: 2.6264 - val_acc: 0.3386\n",
      "Epoch 10/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.5559 - acc: 0.3529 - val_loss: 2.5334 - val_acc: 0.3691\n",
      "Epoch 11/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.5493 - acc: 0.3623 - val_loss: 2.6236 - val_acc: 0.3495\n",
      "Epoch 12/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.5050 - acc: 0.3973 - val_loss: 2.5108 - val_acc: 0.4064\n",
      "Epoch 13/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.5641 - acc: 0.3868 - val_loss: 2.6016 - val_acc: 0.4018\n",
      "Epoch 14/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.5297 - acc: 0.4167 - val_loss: 2.5768 - val_acc: 0.4171\n",
      "Epoch 15/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.5377 - acc: 0.4258 - val_loss: 2.6043 - val_acc: 0.4206\n",
      "Epoch 16/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.5610 - acc: 0.4317 - val_loss: 2.6205 - val_acc: 0.4214\n",
      "Epoch 17/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.5792 - acc: 0.4384 - val_loss: 2.6747 - val_acc: 0.4395\n",
      "Epoch 18/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.6118 - acc: 0.4441 - val_loss: 2.6925 - val_acc: 0.4407\n",
      "Epoch 19/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.6550 - acc: 0.4475 - val_loss: 2.7308 - val_acc: 0.4436\n",
      "Epoch 20/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.6528 - acc: 0.4592 - val_loss: 2.8400 - val_acc: 0.4281\n",
      "Epoch 21/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.7210 - acc: 0.4553 - val_loss: 2.7588 - val_acc: 0.4700\n",
      "Epoch 22/100\n",
      "809/809 [==============================] - 21s 25ms/step - loss: 2.6817 - acc: 0.4865 - val_loss: 2.8620 - val_acc: 0.4394\n",
      "Epoch 23/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.7552 - acc: 0.4768 - val_loss: 2.8398 - val_acc: 0.4786\n",
      "Epoch 24/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 2.8179 - acc: 0.4764 - val_loss: 2.9219 - val_acc: 0.4579\n",
      "Epoch 25/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 2.8726 - acc: 0.4675 - val_loss: 3.0680 - val_acc: 0.4464\n",
      "Epoch 26/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.8962 - acc: 0.4820 - val_loss: 3.0275 - val_acc: 0.4649\n",
      "Epoch 27/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.9333 - acc: 0.4923 - val_loss: 3.0351 - val_acc: 0.4779\n",
      "Epoch 28/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 2.9818 - acc: 0.4942 - val_loss: 3.1703 - val_acc: 0.4533\n",
      "Epoch 29/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 3.0235 - acc: 0.4937 - val_loss: 3.1464 - val_acc: 0.4898\n",
      "Epoch 30/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 3.1005 - acc: 0.4916 - val_loss: 3.2370 - val_acc: 0.4788\n",
      "Epoch 31/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 3.0960 - acc: 0.5068 - val_loss: 3.3272 - val_acc: 0.4710\n",
      "Epoch 32/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 3.1869 - acc: 0.5001 - val_loss: 3.3662 - val_acc: 0.4776\n",
      "Epoch 33/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 3.2832 - acc: 0.4918 - val_loss: 3.4122 - val_acc: 0.4863\n",
      "Epoch 34/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 3.2725 - acc: 0.5146 - val_loss: 3.4457 - val_acc: 0.4910\n",
      "Epoch 35/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 3.3820 - acc: 0.4946 - val_loss: 3.5551 - val_acc: 0.4807\n",
      "Epoch 36/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 3.4371 - acc: 0.4991 - val_loss: 3.6047 - val_acc: 0.4818\n",
      "Epoch 37/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 3.4367 - acc: 0.5207 - val_loss: 3.6479 - val_acc: 0.4921\n",
      "Epoch 38/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 3.4986 - acc: 0.5182 - val_loss: 3.7686 - val_acc: 0.4752\n",
      "Epoch 39/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 3.5934 - acc: 0.5106 - val_loss: 3.6831 - val_acc: 0.5136\n",
      "Epoch 40/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 3.6384 - acc: 0.5141 - val_loss: 3.7788 - val_acc: 0.5191\n",
      "Epoch 41/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 3.6697 - acc: 0.5255 - val_loss: 3.9306 - val_acc: 0.4860\n",
      "Epoch 42/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 3.7735 - acc: 0.5102 - val_loss: 3.9859 - val_acc: 0.4758\n",
      "Epoch 43/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 3.8129 - acc: 0.5151 - val_loss: 3.9788 - val_acc: 0.5029\n",
      "Epoch 44/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 3.8834 - acc: 0.5207 - val_loss: 4.0903 - val_acc: 0.4884\n",
      "Epoch 45/100\n",
      "809/809 [==============================] - 20s 25ms/step - loss: 3.9116 - acc: 0.5322 - val_loss: 4.1264 - val_acc: 0.5040\n",
      "Epoch 46/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 4.0192 - acc: 0.5092 - val_loss: 4.2321 - val_acc: 0.4796\n",
      "Epoch 47/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 4.0444 - acc: 0.5266 - val_loss: 4.2437 - val_acc: 0.5061\n",
      "Epoch 48/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 4.1096 - acc: 0.5268 - val_loss: 4.3092 - val_acc: 0.4997\n",
      "Epoch 49/100\n",
      "809/809 [==============================] - 20s 25ms/step - loss: 4.1267 - acc: 0.5349 - val_loss: 4.3686 - val_acc: 0.5047\n",
      "Epoch 50/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 4.2881 - acc: 0.5114 - val_loss: 4.5197 - val_acc: 0.4707\n",
      "Epoch 51/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 4.2958 - acc: 0.5294 - val_loss: 4.4982 - val_acc: 0.5068\n",
      "Epoch 52/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 4.3701 - acc: 0.5252 - val_loss: 4.5509 - val_acc: 0.5125\n",
      "Epoch 53/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 4.4208 - acc: 0.5312 - val_loss: 4.6438 - val_acc: 0.5070\n",
      "Epoch 54/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 4.4824 - acc: 0.5323 - val_loss: 4.8239 - val_acc: 0.4779\n",
      "Epoch 55/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 4.5869 - acc: 0.5192 - val_loss: 4.7661 - val_acc: 0.5095\n",
      "Epoch 56/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 4.5918 - acc: 0.5347 - val_loss: 4.8050 - val_acc: 0.5139\n",
      "Epoch 57/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 4.7051 - acc: 0.5245 - val_loss: 4.9170 - val_acc: 0.5017\n",
      "Epoch 58/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 4.7420 - acc: 0.5313 - val_loss: 5.0130 - val_acc: 0.4927\n",
      "Epoch 59/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 4.8200 - acc: 0.5316 - val_loss: 5.0219 - val_acc: 0.5166\n",
      "Epoch 60/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 4.8664 - acc: 0.5338 - val_loss: 5.1196 - val_acc: 0.5151\n",
      "Epoch 61/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 4.9422 - acc: 0.5314 - val_loss: 5.1980 - val_acc: 0.5085\n",
      "Epoch 62/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 4.9596 - acc: 0.5467 - val_loss: 5.2620 - val_acc: 0.4855\n",
      "Epoch 63/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 5.0764 - acc: 0.5280 - val_loss: 5.3564 - val_acc: 0.4959\n",
      "Epoch 64/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 5.1559 - acc: 0.5268 - val_loss: 5.2999 - val_acc: 0.5324\n",
      "Epoch 65/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 5.1906 - acc: 0.5349 - val_loss: 5.4789 - val_acc: 0.4899\n",
      "Epoch 66/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 5.2493 - acc: 0.5377 - val_loss: 5.4787 - val_acc: 0.5209\n",
      "Epoch 67/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 5.3301 - acc: 0.5297 - val_loss: 5.6106 - val_acc: 0.5002\n",
      "Epoch 68/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 5.4009 - acc: 0.5358 - val_loss: 5.6028 - val_acc: 0.5150\n",
      "Epoch 69/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 5.3835 - acc: 0.5569 - val_loss: 5.7486 - val_acc: 0.5058\n",
      "Epoch 70/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 5.5915 - acc: 0.5145 - val_loss: 5.7456 - val_acc: 0.5140\n",
      "Epoch 71/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 5.5573 - acc: 0.5409 - val_loss: 5.8057 - val_acc: 0.5194\n",
      "Epoch 72/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 5.6488 - acc: 0.5392 - val_loss: 5.8610 - val_acc: 0.5269\n",
      "Epoch 73/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 5.7117 - acc: 0.5326 - val_loss: 5.8996 - val_acc: 0.5243\n",
      "Epoch 74/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 5.7979 - acc: 0.5338 - val_loss: 6.0928 - val_acc: 0.4992\n",
      "Epoch 75/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 5.8011 - acc: 0.5441 - val_loss: 6.0956 - val_acc: 0.5038\n",
      "Epoch 76/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 5.9078 - acc: 0.5324 - val_loss: 6.1466 - val_acc: 0.5148\n",
      "Epoch 77/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 5.9653 - acc: 0.5348 - val_loss: 6.2439 - val_acc: 0.5113\n",
      "Epoch 78/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 6.0020 - acc: 0.5408 - val_loss: 6.2772 - val_acc: 0.5099\n",
      "Epoch 79/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 6.1028 - acc: 0.5335 - val_loss: 6.3778 - val_acc: 0.5034\n",
      "Epoch 80/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 6.1367 - acc: 0.5367 - val_loss: 6.4075 - val_acc: 0.5093\n",
      "Epoch 81/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 6.2052 - acc: 0.5470 - val_loss: 6.4932 - val_acc: 0.5147\n",
      "Epoch 82/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 6.2382 - acc: 0.5425 - val_loss: 6.5518 - val_acc: 0.5054\n",
      "Epoch 83/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 6.3454 - acc: 0.5347 - val_loss: 6.5002 - val_acc: 0.5345\n",
      "Epoch 84/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 6.3983 - acc: 0.5322 - val_loss: 6.6678 - val_acc: 0.5078\n",
      "Epoch 85/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 6.4441 - acc: 0.5397 - val_loss: 6.7535 - val_acc: 0.5000\n",
      "Epoch 86/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 6.5021 - acc: 0.5383 - val_loss: 6.8104 - val_acc: 0.5051\n",
      "Epoch 87/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 6.5665 - acc: 0.5417 - val_loss: 6.7983 - val_acc: 0.5166\n",
      "Epoch 88/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 6.6400 - acc: 0.5349 - val_loss: 6.8937 - val_acc: 0.5148\n",
      "Epoch 89/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 6.6685 - acc: 0.5427 - val_loss: 6.9248 - val_acc: 0.5176\n",
      "Epoch 90/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 6.7423 - acc: 0.5395 - val_loss: 7.0560 - val_acc: 0.4988\n",
      "Epoch 91/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 6.8202 - acc: 0.5339 - val_loss: 7.0959 - val_acc: 0.5067\n",
      "Epoch 92/100\n",
      "809/809 [==============================] - 20s 25ms/step - loss: 6.8373 - acc: 0.5455 - val_loss: 7.0609 - val_acc: 0.5235\n",
      "Epoch 93/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 6.8808 - acc: 0.5465 - val_loss: 7.2199 - val_acc: 0.4974\n",
      "Epoch 94/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 7.0158 - acc: 0.5278 - val_loss: 7.2504 - val_acc: 0.5097\n",
      "Epoch 95/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 7.0059 - acc: 0.5448 - val_loss: 7.2797 - val_acc: 0.5147\n",
      "Epoch 96/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 7.0911 - acc: 0.5347 - val_loss: 7.3017 - val_acc: 0.5255\n",
      "Epoch 97/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 7.1035 - acc: 0.5488 - val_loss: 7.4094 - val_acc: 0.5060\n",
      "Epoch 98/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 7.2312 - acc: 0.5281 - val_loss: 7.4597 - val_acc: 0.5082\n",
      "Epoch 99/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 7.1894 - acc: 0.5487 - val_loss: 7.5000 - val_acc: 0.5095\n",
      "Epoch 100/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 7.3082 - acc: 0.5344 - val_loss: 7.5683 - val_acc: 0.5158\n"
     ]
    }
   ],
   "source": [
    "pi.build_MLP_model()\n",
    "history_MLP = pi.fit_generator(epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd6374cb908>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd636ff9da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_y = 30\n",
    "x = range(1,len_y+1)\n",
    "y1 = history_BiRNN.history['val_acc'][:len_y]\n",
    "y2 = history_RNN.history['val_acc'][:len_y]\n",
    "y3 = history_CNN.history['val_acc'][:len_y]\n",
    "y4 = history_MLP.history['val_acc'][:len_y]\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "\n",
    "plt.plot(x,y1, 'k-.', label='BiRNN', linewidth=2)\n",
    "plt.plot(x,y2, 'k--', label='RNN', linewidth=1)\n",
    "plt.plot(x,y3, 'k-', label='CNN', linewidth=1)\n",
    "plt.plot(x,y4, 'k:', label='MLP', linewidth=2)\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25 int\n",
    "\n",
    "# RNN, 100 ep return_sequences=True \n",
    "# 13100 30 - loss: 2.9677 - acc: 0.1152\n",
    "# 1310  30 - loss: 2.6313 - acc: 0.2464\n",
    "# 131   30 - loss: 1.8456 - acc: 0.4678\n",
    "# 13    30 - loss: 2.1301 - acc: 0.4263\n",
    "# 1     30 - loss: 2.5108 - acc: 0.2834\n",
    "\n",
    "# BiRNN, 100 ep return_sequences=True\n",
    "# 1310    2s/step - loss: 2.1712 - acc: 0.3397 - val_loss: 2.0868 - val_acc: 0.3754 \n",
    "# 131  199ms/step - loss: 0.7650 - acc: 0.7808 - val_loss: 0.6818 - val_acc: 0.8034\n",
    "# 13    27ms/step - loss: 0.6413 - acc: 0.8194 - val_loss: 0.5457 - val_acc: 0.8517 1-LSTM\n",
    "# 13    30ms/step - loss: 0.6472 - acc: 0.8171 - val_loss: 0.5493 - val_acc: 0.8717 2-LSTM \n",
    "# 13    36ms/step - loss: 0.5443 - acc: 0.8493 - val_loss: 0.4665 - val_acc: 0.8766 3-LSTM \n",
    "# 1     20ms/step - loss: 0.7527 - acc: 0.7846 - val_loss: 0.6238 - val_acc: 0.8288\n",
    "\n",
    "# MLP\n",
    "# 131  199ms/step - loss: 4.6698 - acc: 0.3628 - val_loss: 2.0174 - val_acc: 0.4895\n",
    "# 13  \n",
    "\n",
    "# CNN\n",
    "# 13  27ms/step - loss: 1.9294 - acc: 0.4842 - val_loss: 1.9757 - val_acc: 0.5213"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_intents 6\n"
     ]
    }
   ],
   "source": [
    "pgi = PredictIntent(is_general = True)\n",
    "pgi.batch_size = 13\n",
    "pgi.max_sequence_length = 5\n",
    "pgi.intent_embedding_dim = 10\n",
    "pgi.num_units = 30\n",
    "pgi.validation_split = 0.2\n",
    "pgi.random_state = 42\n",
    "pgi.data_path = \"../feature_and_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 1/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.6340 - acc: 0.2727 - val_loss: 1.6095 - val_acc: 0.2967\n",
      "Epoch 2/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.6057 - acc: 0.2865 - val_loss: 1.6016 - val_acc: 0.2893\n",
      "Epoch 3/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5914 - acc: 0.3022 - val_loss: 1.5844 - val_acc: 0.3205\n",
      "Epoch 4/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5776 - acc: 0.3217 - val_loss: 1.5822 - val_acc: 0.3019\n",
      "Epoch 5/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5602 - acc: 0.3423 - val_loss: 1.5781 - val_acc: 0.3466\n",
      "Epoch 6/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5521 - acc: 0.3547 - val_loss: 1.5300 - val_acc: 0.3709\n",
      "Epoch 7/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5255 - acc: 0.3709 - val_loss: 1.5164 - val_acc: 0.3779\n",
      "Epoch 8/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 1.5126 - acc: 0.3944 - val_loss: 1.5400 - val_acc: 0.3613\n",
      "Epoch 9/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.5044 - acc: 0.3889 - val_loss: 1.5018 - val_acc: 0.3869\n",
      "Epoch 10/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4898 - acc: 0.4004 - val_loss: 1.5192 - val_acc: 0.3839\n",
      "Epoch 11/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4907 - acc: 0.4059 - val_loss: 1.4845 - val_acc: 0.3993\n",
      "Epoch 12/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4719 - acc: 0.4124 - val_loss: 1.5034 - val_acc: 0.3852\n",
      "Epoch 13/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.4875 - acc: 0.4066 - val_loss: 1.4997 - val_acc: 0.4149\n",
      "Epoch 14/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4635 - acc: 0.4163 - val_loss: 1.4848 - val_acc: 0.3986\n",
      "Epoch 15/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4716 - acc: 0.4182 - val_loss: 1.4860 - val_acc: 0.4108\n",
      "Epoch 16/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 1.4568 - acc: 0.4237 - val_loss: 1.4540 - val_acc: 0.4188\n",
      "Epoch 17/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4626 - acc: 0.4232 - val_loss: 1.4755 - val_acc: 0.4113\n",
      "Epoch 18/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4547 - acc: 0.4256 - val_loss: 1.5003 - val_acc: 0.3980\n",
      "Epoch 19/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4589 - acc: 0.4216 - val_loss: 1.4574 - val_acc: 0.4265\n",
      "Epoch 20/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4384 - acc: 0.4393 - val_loss: 1.4795 - val_acc: 0.4235\n",
      "Epoch 21/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4616 - acc: 0.4240 - val_loss: 1.4879 - val_acc: 0.4068\n",
      "Epoch 22/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4379 - acc: 0.4441 - val_loss: 1.4561 - val_acc: 0.4467 1s - loss: 1.4380 - acc: 0.44 - ETA: 1s\n",
      "Epoch 23/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4452 - acc: 0.4284 - val_loss: 1.4585 - val_acc: 0.4157\n",
      "Epoch 24/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4360 - acc: 0.4487 - val_loss: 1.4708 - val_acc: 0.4280\n",
      "Epoch 25/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 1.4349 - acc: 0.4471 - val_loss: 1.4625 - val_acc: 0.4353\n",
      "Epoch 26/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4390 - acc: 0.4429 - val_loss: 1.4693 - val_acc: 0.4333: 0s - loss: 1.4392 - acc: 0.442\n",
      "Epoch 27/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4439 - acc: 0.4448 - val_loss: 1.4632 - val_acc: 0.4328\n",
      "Epoch 28/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.4350 - acc: 0.4460 - val_loss: 1.4486 - val_acc: 0.4430\n",
      "Epoch 29/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4394 - acc: 0.4459 - val_loss: 1.5005 - val_acc: 0.4139\n",
      "Epoch 30/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4291 - acc: 0.4524 - val_loss: 1.4753 - val_acc: 0.4349\n",
      "Epoch 31/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.4335 - acc: 0.4568 - val_loss: 1.4487 - val_acc: 0.4469\n",
      "Epoch 32/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4492 - acc: 0.4460 - val_loss: 1.4404 - val_acc: 0.4474\n",
      "Epoch 33/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4269 - acc: 0.4557 - val_loss: 1.4826 - val_acc: 0.4387\n",
      "Epoch 34/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4355 - acc: 0.4566 - val_loss: 1.4825 - val_acc: 0.4374\n",
      "Epoch 35/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4404 - acc: 0.4511 - val_loss: 1.4717 - val_acc: 0.4387\n",
      "Epoch 36/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4323 - acc: 0.4627 - val_loss: 1.4637 - val_acc: 0.4571\n",
      "Epoch 37/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.4473 - acc: 0.4533 - val_loss: 1.5053 - val_acc: 0.4335\n",
      "Epoch 38/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4442 - acc: 0.4531 - val_loss: 1.4643 - val_acc: 0.4578\n",
      "Epoch 39/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4410 - acc: 0.4624 - val_loss: 1.4806 - val_acc: 0.4460\n",
      "Epoch 40/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4443 - acc: 0.4636 - val_loss: 1.4936 - val_acc: 0.4459\n",
      "Epoch 41/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4557 - acc: 0.4517 - val_loss: 1.4782 - val_acc: 0.4508\n",
      "Epoch 42/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 1.4357 - acc: 0.4737 - val_loss: 1.4955 - val_acc: 0.4423\n",
      "Epoch 43/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4407 - acc: 0.4665 - val_loss: 1.5055 - val_acc: 0.4373\n",
      "Epoch 44/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4725 - acc: 0.4536 - val_loss: 1.4470 - val_acc: 0.4827\n",
      "Epoch 45/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4535 - acc: 0.4606 - val_loss: 1.5216 - val_acc: 0.4205\n",
      "Epoch 46/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4584 - acc: 0.4661 - val_loss: 1.5010 - val_acc: 0.4496\n",
      "Epoch 47/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 1.4569 - acc: 0.4576 - val_loss: 1.5177 - val_acc: 0.4364\n",
      "Epoch 48/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4655 - acc: 0.4577 - val_loss: 1.4718 - val_acc: 0.4740\n",
      "Epoch 49/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4577 - acc: 0.4703 - val_loss: 1.5241 - val_acc: 0.4474\n",
      "Epoch 50/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4602 - acc: 0.4645 - val_loss: 1.4934 - val_acc: 0.4628\n",
      "Epoch 51/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4741 - acc: 0.4672 - val_loss: 1.5176 - val_acc: 0.4440\n",
      "Epoch 52/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4686 - acc: 0.4687 - val_loss: 1.5126 - val_acc: 0.4469\n",
      "Epoch 53/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4728 - acc: 0.4662 - val_loss: 1.5512 - val_acc: 0.4247\n",
      "Epoch 54/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4818 - acc: 0.4671 - val_loss: 1.5319 - val_acc: 0.4464\n",
      "Epoch 55/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.4604 - acc: 0.4746 - val_loss: 1.4799 - val_acc: 0.4745\n",
      "Epoch 56/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4874 - acc: 0.4685 - val_loss: 1.5414 - val_acc: 0.44894828 - acc: 0.4 - ETA: 1s - lo\n",
      "Epoch 57/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4894 - acc: 0.4631 - val_loss: 1.5576 - val_acc: 0.4367\n",
      "Epoch 58/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4866 - acc: 0.4676 - val_loss: 1.5153 - val_acc: 0.4631\n",
      "Epoch 59/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4850 - acc: 0.4768 - val_loss: 1.5318 - val_acc: 0.4592\n",
      "Epoch 60/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4780 - acc: 0.4798 - val_loss: 1.5459 - val_acc: 0.4526\n",
      "Epoch 61/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4975 - acc: 0.4637 - val_loss: 1.5397 - val_acc: 0.4665\n",
      "Epoch 62/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5112 - acc: 0.4602 - val_loss: 1.5287 - val_acc: 0.4515\n",
      "Epoch 63/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4848 - acc: 0.4797 - val_loss: 1.5700 - val_acc: 0.4393\n",
      "Epoch 64/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4954 - acc: 0.4729 - val_loss: 1.5388 - val_acc: 0.4661\n",
      "Epoch 65/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5101 - acc: 0.4666 - val_loss: 1.5651 - val_acc: 0.4577\n",
      "Epoch 66/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5165 - acc: 0.4718 - val_loss: 1.5481 - val_acc: 0.4567\n",
      "Epoch 67/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4931 - acc: 0.4790 - val_loss: 1.5769 - val_acc: 0.4458\n",
      "Epoch 68/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.5158 - acc: 0.4698 - val_loss: 1.5606 - val_acc: 0.4511\n",
      "Epoch 69/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5225 - acc: 0.4726 - val_loss: 1.5555 - val_acc: 0.4622\n",
      "Epoch 70/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5231 - acc: 0.4736 - val_loss: 1.5752 - val_acc: 0.4671\n",
      "Epoch 71/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.5291 - acc: 0.4712 - val_loss: 1.5492 - val_acc: 0.4794\n",
      "Epoch 72/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5264 - acc: 0.4723 - val_loss: 1.6142 - val_acc: 0.4346\n",
      "Epoch 73/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5280 - acc: 0.4777 - val_loss: 1.5954 - val_acc: 0.4543 \n",
      "Epoch 74/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5384 - acc: 0.4732 - val_loss: 1.5838 - val_acc: 0.4623\n",
      "Epoch 75/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5327 - acc: 0.4796 - val_loss: 1.5866 - val_acc: 0.4561\n",
      "Epoch 76/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5373 - acc: 0.4744 - val_loss: 1.5795 - val_acc: 0.4586\n",
      "Epoch 77/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5501 - acc: 0.4694 - val_loss: 1.6104 - val_acc: 0.4508\n",
      "Epoch 78/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5516 - acc: 0.4748 - val_loss: 1.6215 - val_acc: 0.4452\n",
      "Epoch 79/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5511 - acc: 0.4740 - val_loss: 1.6162 - val_acc: 0.4537\n",
      "Epoch 80/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.5626 - acc: 0.4719 - val_loss: 1.6086 - val_acc: 0.4635\n",
      "Epoch 81/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5507 - acc: 0.4768 - val_loss: 1.5811 - val_acc: 0.4789\n",
      "Epoch 82/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5607 - acc: 0.4817 - val_loss: 1.6076 - val_acc: 0.4536\n",
      "Epoch 83/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5723 - acc: 0.4664 - val_loss: 1.6005 - val_acc: 0.4603\n",
      "Epoch 84/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5666 - acc: 0.4764 - val_loss: 1.5987 - val_acc: 0.4717\n",
      "Epoch 85/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5816 - acc: 0.4739 - val_loss: 1.6605 - val_acc: 0.4419\n",
      "Epoch 86/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.5749 - acc: 0.4776 - val_loss: 1.6331 - val_acc: 0.4642\n",
      "Epoch 87/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5879 - acc: 0.4731 - val_loss: 1.6398 - val_acc: 0.4584\n",
      "Epoch 88/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5848 - acc: 0.4835 - val_loss: 1.6194 - val_acc: 0.4737\n",
      "Epoch 89/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5968 - acc: 0.4650 - val_loss: 1.6533 - val_acc: 0.4463\n",
      "Epoch 90/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5737 - acc: 0.4923 - val_loss: 1.6664 - val_acc: 0.4574\n",
      "Epoch 91/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5858 - acc: 0.4801 - val_loss: 1.6145 - val_acc: 0.4776\n",
      "Epoch 92/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.6149 - acc: 0.4694 - val_loss: 1.6668 - val_acc: 0.4501\n",
      "Epoch 93/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.6124 - acc: 0.4741 - val_loss: 1.6566 - val_acc: 0.4702\n",
      "Epoch 94/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5951 - acc: 0.4800 - val_loss: 1.6811 - val_acc: 0.4533\n",
      "Epoch 95/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.5964 - acc: 0.4834 - val_loss: 1.6340 - val_acc: 0.4652\n",
      "Epoch 96/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.6273 - acc: 0.4689 - val_loss: 1.6732 - val_acc: 0.4584\n",
      "Epoch 97/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.6188 - acc: 0.4695 - val_loss: 1.6573 - val_acc: 0.4687\n",
      "Epoch 98/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.6382 - acc: 0.4708 - val_loss: 1.6662 - val_acc: 0.4607\n",
      "Epoch 99/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.6044 - acc: 0.4878 - val_loss: 1.6941 - val_acc: 0.4690\n",
      "Epoch 100/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.6283 - acc: 0.4799 - val_loss: 1.6885 - val_acc: 0.4542\n"
     ]
    }
   ],
   "source": [
    "pgi.build_MLP_model()\n",
    "pgi_MLP = pgi.fit_generator(epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "809/809 [==============================] - 24s 29ms/step - loss: 1.6366 - acc: 0.2521 - val_loss: 1.6416 - val_acc: 0.2652\n",
      "Epoch 2/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.6110 - acc: 0.2838 - val_loss: 1.6007 - val_acc: 0.2952\n",
      "Epoch 3/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5978 - acc: 0.3036 - val_loss: 1.5879 - val_acc: 0.2919: 1s - l\n",
      "Epoch 4/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5834 - acc: 0.3163 - val_loss: 1.5863 - val_acc: 0.3304\n",
      "Epoch 5/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5722 - acc: 0.3272 - val_loss: 1.5415 - val_acc: 0.3446\n",
      "Epoch 6/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5645 - acc: 0.3385 - val_loss: 1.5298 - val_acc: 0.3757\n",
      "Epoch 7/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5627 - acc: 0.3438 - val_loss: 1.5384 - val_acc: 0.3910\n",
      "Epoch 8/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5361 - acc: 0.3617 - val_loss: 1.5153 - val_acc: 0.3872\n",
      "Epoch 9/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5371 - acc: 0.3710 - val_loss: 1.5018 - val_acc: 0.4016\n",
      "Epoch 10/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5164 - acc: 0.3781 - val_loss: 1.4795 - val_acc: 0.4221\n",
      "Epoch 11/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5274 - acc: 0.3784 - val_loss: 1.4861 - val_acc: 0.4123\n",
      "Epoch 12/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5130 - acc: 0.3836 - val_loss: 1.4625 - val_acc: 0.4219\n",
      "Epoch 13/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5070 - acc: 0.3936 - val_loss: 1.4481 - val_acc: 0.4375- ET\n",
      "Epoch 14/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 1.4921 - acc: 0.4069 - val_loss: 1.4749 - val_acc: 0.4464\n",
      "Epoch 15/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5139 - acc: 0.3902 - val_loss: 1.4426 - val_acc: 0.4345\n",
      "Epoch 16/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4873 - acc: 0.4055 - val_loss: 1.4629 - val_acc: 0.4376\n",
      "Epoch 17/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4863 - acc: 0.4120 - val_loss: 1.4125 - val_acc: 0.4672\n",
      "Epoch 18/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.5052 - acc: 0.4003 - val_loss: 1.4801 - val_acc: 0.4289\n",
      "Epoch 19/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4942 - acc: 0.3999 - val_loss: 1.4357 - val_acc: 0.4490oss: 1.4852 - acc - ETA: 1s \n",
      "Epoch 20/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5111 - acc: 0.4025 - val_loss: 1.4580 - val_acc: 0.4401\n",
      "Epoch 21/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.4905 - acc: 0.4094 - val_loss: 1.4320 - val_acc: 0.4495\n",
      "Epoch 22/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.5024 - acc: 0.4026 - val_loss: 1.4251 - val_acc: 0.4588\n",
      "Epoch 23/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5079 - acc: 0.4056 - val_loss: 1.4153 - val_acc: 0.4603\n",
      "Epoch 24/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5076 - acc: 0.4033 - val_loss: 1.4512 - val_acc: 0.4503\n",
      "Epoch 25/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5110 - acc: 0.4027 - val_loss: 1.4518 - val_acc: 0.4450\n",
      "Epoch 26/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.5036 - acc: 0.4035 - val_loss: 1.4271 - val_acc: 0.4593\n",
      "Epoch 27/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5046 - acc: 0.4106 - val_loss: 1.4477 - val_acc: 0.4570\n",
      "Epoch 28/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5214 - acc: 0.3976 - val_loss: 1.4609 - val_acc: 0.4595\n",
      "Epoch 29/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5048 - acc: 0.4076 - val_loss: 1.4525 - val_acc: 0.4567\n",
      "Epoch 30/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5221 - acc: 0.4035 - val_loss: 1.4548 - val_acc: 0.4372\n",
      "Epoch 31/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.4995 - acc: 0.4095 - val_loss: 1.4465 - val_acc: 0.4457\n",
      "Epoch 32/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5232 - acc: 0.4002 - val_loss: 1.4526 - val_acc: 0.4488\n",
      "Epoch 33/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5059 - acc: 0.4077 - val_loss: 1.4168 - val_acc: 0.4658\n",
      "Epoch 34/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5191 - acc: 0.4003 - val_loss: 1.4435 - val_acc: 0.4421\n",
      "Epoch 35/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5079 - acc: 0.4095 - val_loss: 1.4536 - val_acc: 0.4370\n",
      "Epoch 36/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.5106 - acc: 0.4064 - val_loss: 1.4330 - val_acc: 0.4534\n",
      "Epoch 37/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5237 - acc: 0.4044 - val_loss: 1.4404 - val_acc: 0.4627\n",
      "Epoch 38/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5066 - acc: 0.4120 - val_loss: 1.4530 - val_acc: 0.4412\n",
      "Epoch 39/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.5241 - acc: 0.3924 - val_loss: 1.4620 - val_acc: 0.4628\n",
      "Epoch 40/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.5153 - acc: 0.4018 - val_loss: 1.4383 - val_acc: 0.4550\n",
      "Epoch 41/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5186 - acc: 0.4023 - val_loss: 1.4296 - val_acc: 0.4443\n",
      "Epoch 42/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.5113 - acc: 0.3994 - val_loss: 1.4188 - val_acc: 0.4654\n",
      "Epoch 43/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5259 - acc: 0.3965 - val_loss: 1.4422 - val_acc: 0.4514\n",
      "Epoch 44/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5146 - acc: 0.3970 - val_loss: 1.4668 - val_acc: 0.4535 acc:  -\n",
      "Epoch 45/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5160 - acc: 0.4025 - val_loss: 1.4415 - val_acc: 0.4543\n",
      "Epoch 46/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5177 - acc: 0.4000 - val_loss: 1.4820 - val_acc: 0.4271\n",
      "Epoch 47/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 1.5193 - acc: 0.4038 - val_loss: 1.3967 - val_acc: 0.4856ss: - ETA: 0s - loss: 1.5207 -\n",
      "Epoch 48/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5180 - acc: 0.3976 - val_loss: 1.4324 - val_acc: 0.4440\n",
      "Epoch 49/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.5235 - acc: 0.3941 - val_loss: 1.4660 - val_acc: 0.4248\n",
      "Epoch 50/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5197 - acc: 0.4053 - val_loss: 1.4307 - val_acc: 0.4627\n",
      "Epoch 51/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5255 - acc: 0.4025 - val_loss: 1.4689 - val_acc: 0.4464\n",
      "Epoch 52/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.5194 - acc: 0.3940 - val_loss: 1.4622 - val_acc: 0.4378\n",
      "Epoch 53/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5112 - acc: 0.4020 - val_loss: 1.4206 - val_acc: 0.4677\n",
      "Epoch 54/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5179 - acc: 0.3955 - val_loss: 1.4934 - val_acc: 0.4283\n",
      "Epoch 55/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5150 - acc: 0.4006 - val_loss: 1.3993 - val_acc: 0.4771\n",
      "Epoch 56/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5322 - acc: 0.3894 - val_loss: 1.4538 - val_acc: 0.4496\n",
      "Epoch 57/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 1.5213 - acc: 0.3966 - val_loss: 1.5382 - val_acc: 0.42805203 - acc:\n",
      "Epoch 58/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5247 - acc: 0.3915 - val_loss: 1.3909 - val_acc: 0.4767\n",
      "Epoch 59/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 1.5305 - acc: 0.3906 - val_loss: 1.4905 - val_acc: 0.4311\n",
      "Epoch 60/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.5147 - acc: 0.3931 - val_loss: 1.4388 - val_acc: 0.4578\n",
      "Epoch 61/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5338 - acc: 0.3933 - val_loss: 1.4119 - val_acc: 0.4712\n",
      "Epoch 62/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5173 - acc: 0.3925 - val_loss: 1.4619 - val_acc: 0.4479\n",
      "Epoch 63/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5391 - acc: 0.3892 - val_loss: 1.4291 - val_acc: 0.4503\n",
      "Epoch 64/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5235 - acc: 0.3930 - val_loss: 1.4385 - val_acc: 0.4570\n",
      "Epoch 65/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5289 - acc: 0.3897 - val_loss: 1.4490 - val_acc: 0.4423\n",
      "Epoch 66/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 1.5106 - acc: 0.3980 - val_loss: 1.4420 - val_acc: 0.4643\n",
      "Epoch 67/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5254 - acc: 0.3987 - val_loss: 1.4646 - val_acc: 0.4361\n",
      "Epoch 68/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5235 - acc: 0.3971 - val_loss: 1.4462 - val_acc: 0.4563\n",
      "Epoch 69/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.5379 - acc: 0.3920 - val_loss: 1.4444 - val_acc: 0.4393\n",
      "Epoch 70/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5439 - acc: 0.3827 - val_loss: 1.4756 - val_acc: 0.4493\n",
      "Epoch 71/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.5251 - acc: 0.4011 - val_loss: 1.5148 - val_acc: 0.4131\n",
      "Epoch 72/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5283 - acc: 0.3850 - val_loss: 1.4630 - val_acc: 0.4470\n",
      "Epoch 73/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5324 - acc: 0.3901 - val_loss: 1.4762 - val_acc: 0.4404 loss: 1.5331 -\n",
      "Epoch 74/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5322 - acc: 0.3847 - val_loss: 1.4556 - val_acc: 0.4484\n",
      "Epoch 75/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5259 - acc: 0.3942 - val_loss: 1.4722 - val_acc: 0.4404\n",
      "Epoch 76/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5278 - acc: 0.3900 - val_loss: 1.4496 - val_acc: 0.4483\n",
      "Epoch 77/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 1.5369 - acc: 0.3817 - val_loss: 1.4634 - val_acc: 0.4596\n",
      "Epoch 78/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5214 - acc: 0.3942 - val_loss: 1.4856 - val_acc: 0.4201\n",
      "Epoch 79/100\n",
      "809/809 [==============================] - 21s 27ms/step - loss: 1.5392 - acc: 0.3820 - val_loss: 1.5324 - val_acc: 0.3926\n",
      "Epoch 80/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5303 - acc: 0.3891 - val_loss: 1.4650 - val_acc: 0.4591\n",
      "Epoch 81/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5480 - acc: 0.3824 - val_loss: 1.4511 - val_acc: 0.4566\n",
      "Epoch 82/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.5238 - acc: 0.3975 - val_loss: 1.4836 - val_acc: 0.4454\n",
      "Epoch 83/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.5270 - acc: 0.3906 - val_loss: 1.5053 - val_acc: 0.4067\n",
      "Epoch 84/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5495 - acc: 0.3827 - val_loss: 1.4679 - val_acc: 0.4521\n",
      "Epoch 85/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5404 - acc: 0.3799 - val_loss: 1.4667 - val_acc: 0.4457\n",
      "Epoch 86/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5447 - acc: 0.3889 - val_loss: 1.4689 - val_acc: 0.4328\n",
      "Epoch 87/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5202 - acc: 0.3955 - val_loss: 1.4805 - val_acc: 0.4198\n",
      "Epoch 88/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5572 - acc: 0.3718 - val_loss: 1.5248 - val_acc: 0.4263\n",
      "Epoch 89/100\n",
      "809/809 [==============================] - 21s 26ms/step - loss: 1.5197 - acc: 0.3920 - val_loss: 1.4172 - val_acc: 0.4813\n",
      "Epoch 90/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5380 - acc: 0.3851 - val_loss: 1.4691 - val_acc: 0.4264\n",
      "Epoch 91/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5379 - acc: 0.3847 - val_loss: 1.4304 - val_acc: 0.4583\n",
      "Epoch 92/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5399 - acc: 0.3749 - val_loss: 1.4927 - val_acc: 0.4386\n",
      "Epoch 93/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5426 - acc: 0.3751 - val_loss: 1.4612 - val_acc: 0.4488\n",
      "Epoch 94/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5453 - acc: 0.3739 - val_loss: 1.4683 - val_acc: 0.4189\n",
      "Epoch 95/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5465 - acc: 0.3712 - val_loss: 1.4767 - val_acc: 0.4298\n",
      "Epoch 96/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5562 - acc: 0.3785 - val_loss: 1.4557 - val_acc: 0.4448\n",
      "Epoch 97/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5351 - acc: 0.3794 - val_loss: 1.4536 - val_acc: 0.4535\n",
      "Epoch 98/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5531 - acc: 0.3717 - val_loss: 1.4952 - val_acc: 0.4244\n",
      "Epoch 99/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5438 - acc: 0.3782 - val_loss: 1.4340 - val_acc: 0.4516\n",
      "Epoch 100/100\n",
      "809/809 [==============================] - 22s 27ms/step - loss: 1.5378 - acc: 0.3794 - val_loss: 1.4606 - val_acc: 0.4331\n"
     ]
    }
   ],
   "source": [
    "pgi.build_CNN_model()\n",
    "pgi_CNN = pgi.fit_generator(epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "809/809 [==============================] - 26s 33ms/step - loss: 1.5746 - acc: 0.3089 - val_loss: 1.5121 - val_acc: 0.3245\n",
      "Epoch 2/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.5101 - acc: 0.3301 - val_loss: 1.5092 - val_acc: 0.3213\n",
      "Epoch 3/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4966 - acc: 0.3401 - val_loss: 1.4996 - val_acc: 0.3363\n",
      "Epoch 4/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4923 - acc: 0.3459 - val_loss: 1.4940 - val_acc: 0.3369\n",
      "Epoch 5/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4888 - acc: 0.3478 - val_loss: 1.4929 - val_acc: 0.3405\n",
      "Epoch 6/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4822 - acc: 0.3552 - val_loss: 1.4849 - val_acc: 0.3576\n",
      "Epoch 7/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4867 - acc: 0.3532 - val_loss: 1.4789 - val_acc: 0.3599\n",
      "Epoch 8/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4830 - acc: 0.3554 - val_loss: 1.4685 - val_acc: 0.3717\n",
      "Epoch 9/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4786 - acc: 0.3600 - val_loss: 1.4829 - val_acc: 0.3588\n",
      "Epoch 10/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4753 - acc: 0.3618 - val_loss: 1.4746 - val_acc: 0.3764\n",
      "Epoch 11/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4866 - acc: 0.3588 - val_loss: 1.4809 - val_acc: 0.3620.48 - ETA: 3s - loss: 1.4841 - acc: 0.  - ETA: 0s - loss: 1.4863 - ac\n",
      "Epoch 12/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4790 - acc: 0.3618 - val_loss: 1.4696 - val_acc: 0.3753\n",
      "Epoch 13/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4652 - acc: 0.3701 - val_loss: 1.4743 - val_acc: 0.3640\n",
      "Epoch 14/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4671 - acc: 0.3734 - val_loss: 1.4745 - val_acc: 0.3645\n",
      "Epoch 15/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4750 - acc: 0.3651 - val_loss: 1.4692 - val_acc: 0.3674\n",
      "Epoch 16/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4688 - acc: 0.3713 - val_loss: 1.4887 - val_acc: 0.3598\n",
      "Epoch 17/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4713 - acc: 0.3706 - val_loss: 1.4449 - val_acc: 0.3867\n",
      "Epoch 18/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4662 - acc: 0.3765 - val_loss: 1.4735 - val_acc: 0.3691\n",
      "Epoch 19/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4616 - acc: 0.3769 - val_loss: 1.4713 - val_acc: 0.3688\n",
      "Epoch 20/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4703 - acc: 0.3734 - val_loss: 1.4534 - val_acc: 0.3920\n",
      "Epoch 21/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4655 - acc: 0.3756 - val_loss: 1.4587 - val_acc: 0.3706\n",
      "Epoch 22/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4524 - acc: 0.3883 - val_loss: 1.4744 - val_acc: 0.3804\n",
      "Epoch 23/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4520 - acc: 0.3856 - val_loss: 1.4475 - val_acc: 0.3853\n",
      "Epoch 24/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4617 - acc: 0.3790 - val_loss: 1.4596 - val_acc: 0.3898\n",
      "Epoch 25/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4577 - acc: 0.3855 - val_loss: 1.4594 - val_acc: 0.3855\n",
      "Epoch 26/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4569 - acc: 0.3846 - val_loss: 1.4546 - val_acc: 0.3882\n",
      "Epoch 27/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4567 - acc: 0.3841 - val_loss: 1.4477 - val_acc: 0.3908\n",
      "Epoch 28/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4521 - acc: 0.3893 - val_loss: 1.4511 - val_acc: 0.4029s: 1.451 - ETA: 1s - loss: 1\n",
      "Epoch 29/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4486 - acc: 0.3934 - val_loss: 1.4464 - val_acc: 0.3953\n",
      "Epoch 30/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4558 - acc: 0.3828 - val_loss: 1.4447 - val_acc: 0.3965\n",
      "Epoch 31/100\n",
      "809/809 [==============================] - 22s 28ms/step - loss: 1.4516 - acc: 0.3859 - val_loss: 1.4465 - val_acc: 0.3893\n",
      "Epoch 32/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4463 - acc: 0.3944 - val_loss: 1.4329 - val_acc: 0.4105\n",
      "Epoch 33/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4392 - acc: 0.4011 - val_loss: 1.4423 - val_acc: 0.3931\n",
      "Epoch 34/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4467 - acc: 0.3923 - val_loss: 1.4450 - val_acc: 0.3954\n",
      "Epoch 35/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4416 - acc: 0.3955 - val_loss: 1.4249 - val_acc: 0.4059\n",
      "Epoch 36/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4418 - acc: 0.3944 - val_loss: 1.4243 - val_acc: 0.4053\n",
      "Epoch 37/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4411 - acc: 0.3971 - val_loss: 1.4518 - val_acc: 0.3929\n",
      "Epoch 38/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4486 - acc: 0.3900 - val_loss: 1.4152 - val_acc: 0.4173\n",
      "Epoch 39/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4363 - acc: 0.4005 - val_loss: 1.4514 - val_acc: 0.3859\n",
      "Epoch 40/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4397 - acc: 0.4000 - val_loss: 1.4327 - val_acc: 0.3989\n",
      "Epoch 41/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4330 - acc: 0.4013 - val_loss: 1.4190 - val_acc: 0.4179\n",
      "Epoch 42/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4302 - acc: 0.4037 - val_loss: 1.4309 - val_acc: 0.4060- loss: 1.4294 \n",
      "Epoch 43/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4384 - acc: 0.3977 - val_loss: 1.4156 - val_acc: 0.4157\n",
      "Epoch 44/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4335 - acc: 0.4023 - val_loss: 1.4411 - val_acc: 0.3971\n",
      "Epoch 45/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4320 - acc: 0.4051 - val_loss: 1.4110 - val_acc: 0.4173 - loss: 1.4315 - acc\n",
      "Epoch 46/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4368 - acc: 0.4032 - val_loss: 1.4177 - val_acc: 0.4099\n",
      "Epoch 47/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4343 - acc: 0.4018 - val_loss: 1.4170 - val_acc: 0.4147 1.433\n",
      "Epoch 48/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4279 - acc: 0.4025 - val_loss: 1.4015 - val_acc: 0.4237\n",
      "Epoch 49/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4339 - acc: 0.4020 - val_loss: 1.4204 - val_acc: 0.4182\n",
      "Epoch 50/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4288 - acc: 0.4076 - val_loss: 1.4264 - val_acc: 0.4018\n",
      "Epoch 51/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4285 - acc: 0.4075 - val_loss: 1.4224 - val_acc: 0.4103\n",
      "Epoch 52/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4271 - acc: 0.4068 - val_loss: 1.4162 - val_acc: 0.4165\n",
      "Epoch 53/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4271 - acc: 0.4091 - val_loss: 1.4170 - val_acc: 0.4159\n",
      "Epoch 54/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4262 - acc: 0.4097 - val_loss: 1.4045 - val_acc: 0.4215\n",
      "Epoch 55/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4208 - acc: 0.4102 - val_loss: 1.4008 - val_acc: 0.4252 ETA: 0s - loss: 1.4194 - ac\n",
      "Epoch 56/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4237 - acc: 0.4088 - val_loss: 1.4268 - val_acc: 0.4106\n",
      "Epoch 57/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4245 - acc: 0.4091 - val_loss: 1.4066 - val_acc: 0.4198\n",
      "Epoch 58/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4284 - acc: 0.4083 - val_loss: 1.4156 - val_acc: 0.4146: 0\n",
      "Epoch 59/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4190 - acc: 0.4136 - val_loss: 1.3989 - val_acc: 0.4269\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4234 - acc: 0.4094 - val_loss: 1.4187 - val_acc: 0.4146\n",
      "Epoch 61/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4205 - acc: 0.4116 - val_loss: 1.4015 - val_acc: 0.4276: 0s - loss: 1.4191 - acc: 0\n",
      "Epoch 62/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4221 - acc: 0.4101 - val_loss: 1.4162 - val_acc: 0.4126\n",
      "Epoch 63/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4183 - acc: 0.4130 - val_loss: 1.4014 - val_acc: 0.4264\n",
      "Epoch 64/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4209 - acc: 0.4109 - val_loss: 1.4098 - val_acc: 0.4209\n",
      "Epoch 65/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4218 - acc: 0.4107 - val_loss: 1.3995 - val_acc: 0.4265\n",
      "Epoch 66/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4170 - acc: 0.4131 - val_loss: 1.4002 - val_acc: 0.4263\n",
      "Epoch 67/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4194 - acc: 0.4126 - val_loss: 1.4001 - val_acc: 0.4249\n",
      "Epoch 68/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4114 - acc: 0.4193 - val_loss: 1.4106 - val_acc: 0.4209\n",
      "Epoch 69/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4206 - acc: 0.4103 - val_loss: 1.3956 - val_acc: 0.4293\n",
      "Epoch 70/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4231 - acc: 0.4077 - val_loss: 1.3965 - val_acc: 0.4334\n",
      "Epoch 71/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4155 - acc: 0.4157 - val_loss: 1.4062 - val_acc: 0.4170\n",
      "Epoch 72/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4193 - acc: 0.4137 - val_loss: 1.4002 - val_acc: 0.4160\n",
      "Epoch 73/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4113 - acc: 0.4150 - val_loss: 1.3997 - val_acc: 0.4264\n",
      "Epoch 74/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4184 - acc: 0.4125 - val_loss: 1.4069 - val_acc: 0.4221\n",
      "Epoch 75/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4152 - acc: 0.4132 - val_loss: 1.4008 - val_acc: 0.4168\n",
      "Epoch 76/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4158 - acc: 0.4158 - val_loss: 1.3966 - val_acc: 0.4308\n",
      "Epoch 77/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4122 - acc: 0.4159 - val_loss: 1.4014 - val_acc: 0.4197\n",
      "Epoch 78/100\n",
      "809/809 [==============================] - 24s 29ms/step - loss: 1.4102 - acc: 0.4197 - val_loss: 1.4003 - val_acc: 0.4294\n",
      "Epoch 79/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4131 - acc: 0.4176 - val_loss: 1.3961 - val_acc: 0.4221\n",
      "Epoch 80/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4215 - acc: 0.4145 - val_loss: 1.3967 - val_acc: 0.4265\n",
      "Epoch 81/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4048 - acc: 0.4214 - val_loss: 1.3978 - val_acc: 0.4232\n",
      "Epoch 82/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4184 - acc: 0.4151 - val_loss: 1.4008 - val_acc: 0.4271\n",
      "Epoch 83/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4112 - acc: 0.4167 - val_loss: 1.3913 - val_acc: 0.4298\n",
      "Epoch 84/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4197 - acc: 0.4133 - val_loss: 1.3916 - val_acc: 0.4295\n",
      "Epoch 85/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4087 - acc: 0.4181 - val_loss: 1.3812 - val_acc: 0.4336\n",
      "Epoch 86/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4230 - acc: 0.4108 - val_loss: 1.4122 - val_acc: 0.4172\n",
      "Epoch 87/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4093 - acc: 0.4197 - val_loss: 1.3960 - val_acc: 0.4240\n",
      "Epoch 88/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4120 - acc: 0.4154 - val_loss: 1.3905 - val_acc: 0.4295\n",
      "Epoch 89/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4096 - acc: 0.4198 - val_loss: 1.3883 - val_acc: 0.4283\n",
      "Epoch 90/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4148 - acc: 0.4157 - val_loss: 1.4037 - val_acc: 0.4217\n",
      "Epoch 91/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4121 - acc: 0.4165 - val_loss: 1.3977 - val_acc: 0.4293\n",
      "Epoch 92/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4137 - acc: 0.4154 - val_loss: 1.3951 - val_acc: 0.4314\n",
      "Epoch 93/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4062 - acc: 0.4228 - val_loss: 1.3710 - val_acc: 0.4356\n",
      "Epoch 94/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4100 - acc: 0.4193 - val_loss: 1.4034 - val_acc: 0.4206\n",
      "Epoch 95/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4153 - acc: 0.4150 - val_loss: 1.3972 - val_acc: 0.4335\n",
      "Epoch 96/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4138 - acc: 0.4182 - val_loss: 1.3829 - val_acc: 0.4313\n",
      "Epoch 97/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4080 - acc: 0.4174 - val_loss: 1.4000 - val_acc: 0.4255\n",
      "Epoch 98/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4149 - acc: 0.4149 - val_loss: 1.3801 - val_acc: 0.4361\n",
      "Epoch 99/100\n",
      "809/809 [==============================] - 23s 29ms/step - loss: 1.4083 - acc: 0.4215 - val_loss: 1.4031 - val_acc: 0.4198\n",
      "Epoch 100/100\n",
      "809/809 [==============================] - 23s 28ms/step - loss: 1.4104 - acc: 0.4191 - val_loss: 1.3956 - val_acc: 0.4295\n"
     ]
    }
   ],
   "source": [
    "pgi.build_RNN_model()\n",
    "pgi_RNN = pgi.fit_generator(epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "809/809 [==============================] - 29s 36ms/step - loss: 1.2450 - acc: 0.4709 - val_loss: 0.8934 - val_acc: 0.6451\n",
      "Epoch 2/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.6425 - acc: 0.7434 - val_loss: 0.4245 - val_acc: 0.8201\n",
      "Epoch 3/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.4368 - acc: 0.8130 - val_loss: 0.4122 - val_acc: 0.8154\n",
      "Epoch 4/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.4157 - acc: 0.8157 - val_loss: 0.4021 - val_acc: 0.8203\n",
      "Epoch 5/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.4118 - acc: 0.8166 - val_loss: 0.4019 - val_acc: 0.8244\n",
      "Epoch 6/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.4061 - acc: 0.8200 - val_loss: 0.3960 - val_acc: 0.8298 1s - los\n",
      "Epoch 7/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.4023 - acc: 0.8236 - val_loss: 0.3934 - val_acc: 0.8313\n",
      "Epoch 8/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3982 - acc: 0.8266 - val_loss: 0.3885 - val_acc: 0.8312\n",
      "Epoch 9/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3975 - acc: 0.8278 - val_loss: 0.3914 - val_acc: 0.8344\n",
      "Epoch 10/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3923 - acc: 0.8323 - val_loss: 0.3844 - val_acc: 0.8399\n",
      "Epoch 11/100\n",
      "809/809 [==============================] - 25s 30ms/step - loss: 0.3906 - acc: 0.8326 - val_loss: 0.3855 - val_acc: 0.8395\n",
      "Epoch 12/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3885 - acc: 0.8343 - val_loss: 0.3743 - val_acc: 0.8462\n",
      "Epoch 13/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3865 - acc: 0.8373 - val_loss: 0.3755 - val_acc: 0.8439\n",
      "Epoch 14/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3852 - acc: 0.8380 - val_loss: 0.3738 - val_acc: 0.8484\n",
      "Epoch 15/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3826 - acc: 0.8405 - val_loss: 0.3604 - val_acc: 0.8545\n",
      "Epoch 16/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3797 - acc: 0.8414 - val_loss: 0.3704 - val_acc: 0.8494\n",
      "Epoch 17/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3789 - acc: 0.8427 - val_loss: 0.3592 - val_acc: 0.8564\n",
      "Epoch 18/100\n",
      "809/809 [==============================] - 25s 30ms/step - loss: 0.3752 - acc: 0.8457 - val_loss: 0.3541 - val_acc: 0.8620\n",
      "Epoch 19/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3738 - acc: 0.8454 - val_loss: 0.3575 - val_acc: 0.8586\n",
      "Epoch 20/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3719 - acc: 0.8472 - val_loss: 0.3592 - val_acc: 0.8548\n",
      "Epoch 21/100\n",
      "809/809 [==============================] - 25s 30ms/step - loss: 0.3703 - acc: 0.8476 - val_loss: 0.3564 - val_acc: 0.8577\n",
      "Epoch 22/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3702 - acc: 0.8474 - val_loss: 0.3460 - val_acc: 0.8638\n",
      "Epoch 23/100\n",
      "809/809 [==============================] - 24s 30ms/step - loss: 0.3652 - acc: 0.8501 - val_loss: 0.3498 - val_acc: 0.8625\n",
      "Epoch 24/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3676 - acc: 0.8507 - val_loss: 0.3491 - val_acc: 0.8617\n",
      "Epoch 25/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3621 - acc: 0.8524 - val_loss: 0.3477 - val_acc: 0.8646\n",
      "Epoch 26/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3663 - acc: 0.8493 - val_loss: 0.3420 - val_acc: 0.8651\n",
      "Epoch 27/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3645 - acc: 0.8507 - val_loss: 0.3409 - val_acc: 0.8667\n",
      "Epoch 28/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3612 - acc: 0.8532 - val_loss: 0.3434 - val_acc: 0.8654\n",
      "Epoch 29/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3587 - acc: 0.8544 - val_loss: 0.3428 - val_acc: 0.8672\n",
      "Epoch 30/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3601 - acc: 0.8546 - val_loss: 0.3402 - val_acc: 0.8665\n",
      "Epoch 31/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3583 - acc: 0.8553 - val_loss: 0.3407 - val_acc: 0.8654\n",
      "Epoch 32/100\n",
      "809/809 [==============================] - 25s 30ms/step - loss: 0.3579 - acc: 0.8546 - val_loss: 0.3317 - val_acc: 0.8709\n",
      "Epoch 33/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3570 - acc: 0.8555 - val_loss: 0.3309 - val_acc: 0.8703\n",
      "Epoch 34/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3553 - acc: 0.8550 - val_loss: 0.3384 - val_acc: 0.8661\n",
      "Epoch 35/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3563 - acc: 0.8547 - val_loss: 0.3421 - val_acc: 0.8658\n",
      "Epoch 36/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3585 - acc: 0.8558 - val_loss: 0.3307 - val_acc: 0.8725\n",
      "Epoch 37/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3553 - acc: 0.8563 - val_loss: 0.3311 - val_acc: 0.8721\n",
      "Epoch 38/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3530 - acc: 0.8577 - val_loss: 0.3339 - val_acc: 0.8705\n",
      "Epoch 39/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3544 - acc: 0.8571 - val_loss: 0.3344 - val_acc: 0.8690\n",
      "Epoch 40/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3560 - acc: 0.8575 - val_loss: 0.3269 - val_acc: 0.8713\n",
      "Epoch 41/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3538 - acc: 0.8572 - val_loss: 0.3353 - val_acc: 0.8675\n",
      "Epoch 42/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3550 - acc: 0.8566 - val_loss: 0.3331 - val_acc: 0.8710\n",
      "Epoch 43/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3502 - acc: 0.8603 - val_loss: 0.3284 - val_acc: 0.8729\n",
      "Epoch 44/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3518 - acc: 0.8585 - val_loss: 0.3348 - val_acc: 0.8684\n",
      "Epoch 45/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3502 - acc: 0.8593 - val_loss: 0.3302 - val_acc: 0.8700\n",
      "Epoch 46/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3452 - acc: 0.8619 - val_loss: 0.3252 - val_acc: 0.8707\n",
      "Epoch 47/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3491 - acc: 0.8590 - val_loss: 0.3312 - val_acc: 0.8722\n",
      "Epoch 48/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3498 - acc: 0.8582 - val_loss: 0.3261 - val_acc: 0.8725\n",
      "Epoch 49/100\n",
      "809/809 [==============================] - 25s 30ms/step - loss: 0.3459 - acc: 0.8602 - val_loss: 0.3345 - val_acc: 0.8695\n",
      "Epoch 50/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3502 - acc: 0.8592 - val_loss: 0.3176 - val_acc: 0.8770\n",
      "Epoch 51/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3475 - acc: 0.8602 - val_loss: 0.3246 - val_acc: 0.8730\n",
      "Epoch 52/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3463 - acc: 0.8609 - val_loss: 0.3318 - val_acc: 0.8695463 - acc\n",
      "Epoch 53/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3461 - acc: 0.8593 - val_loss: 0.3203 - val_acc: 0.8770\n",
      "Epoch 54/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3497 - acc: 0.8589 - val_loss: 0.3279 - val_acc: 0.8714\n",
      "Epoch 55/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3466 - acc: 0.8600 - val_loss: 0.3232 - val_acc: 0.8744\n",
      "Epoch 56/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3455 - acc: 0.8603 - val_loss: 0.3326 - val_acc: 0.8705\n",
      "Epoch 57/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3440 - acc: 0.8638 - val_loss: 0.3257 - val_acc: 0.8736\n",
      "Epoch 58/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3469 - acc: 0.8599 - val_loss: 0.3188 - val_acc: 0.8755\n",
      "Epoch 59/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3457 - acc: 0.8609 - val_loss: 0.3247 - val_acc: 0.8731\n",
      "Epoch 60/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3432 - acc: 0.8630 - val_loss: 0.3227 - val_acc: 0.8723\n",
      "Epoch 61/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3465 - acc: 0.8608 - val_loss: 0.3292 - val_acc: 0.8738\n",
      "Epoch 62/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3458 - acc: 0.8613 - val_loss: 0.3247 - val_acc: 0.8720: 7 - ETA: 3s - loss: 0 - ETA: 2s - ETA: 0s - loss: 0.3454 - acc: 0.8 - ETA: 0s - loss: 0.3453 - acc: 0\n",
      "Epoch 63/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3408 - acc: 0.8640 - val_loss: 0.3229 - val_acc: 0.8744\n",
      "Epoch 64/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3477 - acc: 0.8587 - val_loss: 0.3264 - val_acc: 0.8732\n",
      "Epoch 65/100\n",
      "809/809 [==============================] - 24s 30ms/step - loss: 0.3402 - acc: 0.8646 - val_loss: 0.3207 - val_acc: 0.8734\n",
      "Epoch 66/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3433 - acc: 0.8619 - val_loss: 0.3163 - val_acc: 0.8770\n",
      "Epoch 67/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3465 - acc: 0.8612 - val_loss: 0.3315 - val_acc: 0.8716\n",
      "Epoch 68/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3434 - acc: 0.8627 - val_loss: 0.3251 - val_acc: 0.8730\n",
      "Epoch 69/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3438 - acc: 0.8609 - val_loss: 0.3227 - val_acc: 0.8744\n",
      "Epoch 70/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3439 - acc: 0.8619 - val_loss: 0.3195 - val_acc: 0.8755\n",
      "Epoch 71/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3452 - acc: 0.8610 - val_loss: 0.3227 - val_acc: 0.8762\n",
      "Epoch 72/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3430 - acc: 0.8616 - val_loss: 0.3324 - val_acc: 0.8641\n",
      "Epoch 73/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3411 - acc: 0.8639 - val_loss: 0.3137 - val_acc: 0.8804\n",
      "Epoch 74/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3442 - acc: 0.8630 - val_loss: 0.3268 - val_acc: 0.8681\n",
      "Epoch 75/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3385 - acc: 0.8640 - val_loss: 0.3240 - val_acc: 0.8766\n",
      "Epoch 76/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3404 - acc: 0.8640 - val_loss: 0.3175 - val_acc: 0.8778\n",
      "Epoch 77/100\n",
      "809/809 [==============================] - 25s 30ms/step - loss: 0.3424 - acc: 0.8636 - val_loss: 0.3191 - val_acc: 0.8774\n",
      "Epoch 78/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3384 - acc: 0.8632 - val_loss: 0.3218 - val_acc: 0.8750\n",
      "Epoch 79/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3434 - acc: 0.8619 - val_loss: 0.3247 - val_acc: 0.8725\n",
      "Epoch 80/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3405 - acc: 0.8640 - val_loss: 0.3189 - val_acc: 0.8760\n",
      "Epoch 81/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3398 - acc: 0.8641 - val_loss: 0.3188 - val_acc: 0.8780\n",
      "Epoch 82/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3416 - acc: 0.8639 - val_loss: 0.3204 - val_acc: 0.8727\n",
      "Epoch 83/100\n",
      "809/809 [==============================] - 25s 30ms/step - loss: 0.3433 - acc: 0.8613 - val_loss: 0.3195 - val_acc: 0.8765\n",
      "Epoch 84/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3376 - acc: 0.8653 - val_loss: 0.3222 - val_acc: 0.8720\n",
      "Epoch 85/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3393 - acc: 0.8644 - val_loss: 0.3250 - val_acc: 0.8729\n",
      "Epoch 86/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3410 - acc: 0.8628 - val_loss: 0.3245 - val_acc: 0.8724\n",
      "Epoch 87/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3374 - acc: 0.8654 - val_loss: 0.3103 - val_acc: 0.8779\n",
      "Epoch 88/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3411 - acc: 0.8629 - val_loss: 0.3257 - val_acc: 0.8740\n",
      "Epoch 89/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3414 - acc: 0.8637 - val_loss: 0.3192 - val_acc: 0.8757\n",
      "Epoch 90/100\n",
      "809/809 [==============================] - 24s 30ms/step - loss: 0.3374 - acc: 0.8645 - val_loss: 0.3151 - val_acc: 0.8762\n",
      "Epoch 91/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3409 - acc: 0.8633 - val_loss: 0.3189 - val_acc: 0.8738\n",
      "Epoch 92/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3390 - acc: 0.8642 - val_loss: 0.3240 - val_acc: 0.8738\n",
      "Epoch 93/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3401 - acc: 0.8646 - val_loss: 0.3220 - val_acc: 0.8755\n",
      "Epoch 94/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3392 - acc: 0.8651 - val_loss: 0.3254 - val_acc: 0.8705\n",
      "Epoch 95/100\n",
      "809/809 [==============================] - 25s 30ms/step - loss: 0.3393 - acc: 0.8639 - val_loss: 0.3078 - val_acc: 0.8825\n",
      "Epoch 96/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3360 - acc: 0.8648 - val_loss: 0.3211 - val_acc: 0.8735\n",
      "Epoch 97/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3420 - acc: 0.8617 - val_loss: 0.3203 - val_acc: 0.8758\n",
      "Epoch 98/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3368 - acc: 0.8636 - val_loss: 0.3233 - val_acc: 0.8727\n",
      "Epoch 99/100\n",
      "809/809 [==============================] - 25s 30ms/step - loss: 0.3362 - acc: 0.8652 - val_loss: 0.3172 - val_acc: 0.8747\n",
      "Epoch 100/100\n",
      "809/809 [==============================] - 25s 31ms/step - loss: 0.3389 - acc: 0.8639 - val_loss: 0.3097 - val_acc: 0.8786\n"
     ]
    }
   ],
   "source": [
    "pgi.build_BiRNN_model()\n",
    "pgi_BiRNN = pgi.fit_generator(epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd6063f9cf8>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd603420240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_y = 30\n",
    "x = range(1,len_y+1)\n",
    "y1 = pgi_BiRNN.history['val_acc'][:len_y]\n",
    "y2 = pgi_RNN.history['val_acc'][:len_y]\n",
    "y3 = pgi_CNN.history['val_acc'][:len_y]\n",
    "y4 = pgi_MLP.history['val_acc'][:len_y]\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(x,y1, 'k-.', label='BiRNN', linewidth=2)\n",
    "plt.plot(x,y2, 'k--', label='RNN', linewidth=1)\n",
    "plt.plot(x,y3, 'k-', label='CNN', linewidth=1)\n",
    "plt.plot(x,y4, 'k:', label='MLP', linewidth=2)\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 int\n",
    "\n",
    "# BiRNN, 100 ep return_sequences=True\n",
    "# 1310    2s/step - loss: 0.4004 - acc: 0.8233 - val_loss: 0.3927 - val_acc: 0.8307\n",
    "# 131  202ms/step - loss: 0.3991 - acc: 0.8246 - val_loss: 0.3849 - val_acc: 0.8351\n",
    "# 13    30ms/step - loss: 0.3388 - acc: 0.8653 - val_loss: 0.3095 - val_acc: 0.8784\n",
    "# 1     20ms/step - loss: 0.4259 - acc: 0.8244 - val_loss: 0.3680 - val_acc: 0.8561\n",
    "\n",
    "# RNN\n",
    "# 131 206ms/step - loss: 1.4664 - acc: 0.3696 - val_loss: 1.4653 - val_acc: 0.3773\n",
    "# 13   28ms/step - loss: 1.4245 - acc: 0.4066 - val_loss: 1.3987 - val_acc: 0.4333\n",
    "\n",
    "# MLP\n",
    "# 131 200ms/step - loss: 6.7115 - acc: 0.2221 - val_loss: 4.0133 - val_acc: 0.2400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID of comment</th>\n",
       "      <th>ID of post</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Intent analysis</th>\n",
       "      <th>Content analysis</th>\n",
       "      <th>Distance to parent</th>\n",
       "      <th>Distance to post</th>\n",
       "      <th>Doc2Vec value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79701</td>\n",
       "      <td>79701</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1.1102230246251565e-16</td>\n",
       "      <td>[-0.033691 -0.037016 0.029007 0.008522 -0.0166...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79702</td>\n",
       "      <td>79701</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "      <td>1.017779691860642</td>\n",
       "      <td>1.017779691860642</td>\n",
       "      <td>[-0.020174 0.017773 0.023126 0.017003 0.041832...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79710</td>\n",
       "      <td>79701</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>30</td>\n",
       "      <td>1.0368699725836679</td>\n",
       "      <td>1.0201519054057373</td>\n",
       "      <td>[0.024097 0.024659 -0.037547 0.032659 0.078938...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79711</td>\n",
       "      <td>79701</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>40</td>\n",
       "      <td>0.8629165321940944</td>\n",
       "      <td>0.9791444162880745</td>\n",
       "      <td>[0.027835 -0.014688 -0.047072 0.005525 0.02313...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID of comment ID of post Likes Intent analysis Content analysis  \\\n",
       "0         79701      79701     0                                    \n",
       "1         79702      79701     2                              20   \n",
       "2         79710      79701     0                              30   \n",
       "3         79711      79701     0                              40   \n",
       "\n",
       "   Distance to parent        Distance to post  \\\n",
       "0                   0  1.1102230246251565e-16   \n",
       "1   1.017779691860642       1.017779691860642   \n",
       "2  1.0368699725836679      1.0201519054057373   \n",
       "3  0.8629165321940944      0.9791444162880745   \n",
       "\n",
       "                                       Doc2Vec value  \n",
       "0  [-0.033691 -0.037016 0.029007 0.008522 -0.0166...  \n",
       "1  [-0.020174 0.017773 0.023126 0.017003 0.041832...  \n",
       "2  [0.024097 0.024659 -0.037547 0.032659 0.078938...  \n",
       "3  [0.027835 -0.014688 -0.047072 0.005525 0.02313...  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_hdf(r'C:\\\\Users\\\\Nikolay\\\\Desktop\\\\coll\\\\8-Nabokova-comm_rosbalt_39_79701_output_10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID of comment</th>\n",
       "      <th>ID of post</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Intent analysis</th>\n",
       "      <th>Content analysis</th>\n",
       "      <th>Distance to parent</th>\n",
       "      <th>Distance to post</th>\n",
       "      <th>Doc2Vec value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79701</td>\n",
       "      <td>79701</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1.1102230246251565e-16</td>\n",
       "      <td>[-0.033691 -0.037016 0.029007 0.008522 -0.0166...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79744</td>\n",
       "      <td>79701</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.7546659771982847</td>\n",
       "      <td>0.7546659771982847</td>\n",
       "      <td>[-0.028849 -0.061239 -0.010560 0.016685 0.0027...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79751</td>\n",
       "      <td>79701</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.03985187965879533</td>\n",
       "      <td>0.7871806515179766</td>\n",
       "      <td>[-0.030819 -0.058584 -0.000901 -0.006251 -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79752</td>\n",
       "      <td>79701</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.0747844151326491</td>\n",
       "      <td>0.7804029784202833</td>\n",
       "      <td>[-0.026400 -0.050600 -0.030745 0.025348 0.0184...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79753</td>\n",
       "      <td>79701</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.02709519911693259</td>\n",
       "      <td>0.7546659771982847</td>\n",
       "      <td>[-0.028849 -0.061239 -0.010560 0.016685 0.0027...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>79776</td>\n",
       "      <td>79701</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.8295794789631287</td>\n",
       "      <td>0.25084034344965744</td>\n",
       "      <td>[-0.031889 -0.025769 0.032461 -0.006925 0.0022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>79778</td>\n",
       "      <td>79701</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.29660776038825853</td>\n",
       "      <td>0.31471159422776296</td>\n",
       "      <td>[-0.018071 -0.009378 0.044637 0.006586 -0.0093...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>79783</td>\n",
       "      <td>79701</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.47136354315643714</td>\n",
       "      <td>0.4983164208788222</td>\n",
       "      <td>[-0.022603 0.006730 0.019023 -0.011535 -0.0062...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>79784</td>\n",
       "      <td>79701</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.48448361443915877</td>\n",
       "      <td>0.2562199197554267</td>\n",
       "      <td>[-0.004581 -0.021733 0.019696 0.011457 0.00209...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID of comment ID of post Likes Intent analysis Content analysis  \\\n",
       "0         79701      79701     0                                    \n",
       "1         79744      79701     0                               4   \n",
       "2         79751      79701     1                               4   \n",
       "3         79752      79701     1                               4   \n",
       "4         79753      79701     1                               4   \n",
       "5         79776      79701     3                               4   \n",
       "6         79778      79701     0                               4   \n",
       "7         79783      79701     0                               4   \n",
       "8         79784      79701     0                               4   \n",
       "\n",
       "    Distance to parent        Distance to post  \\\n",
       "0                    0  1.1102230246251565e-16   \n",
       "1   0.7546659771982847      0.7546659771982847   \n",
       "2  0.03985187965879533      0.7871806515179766   \n",
       "3   0.0747844151326491      0.7804029784202833   \n",
       "4  0.02709519911693259      0.7546659771982847   \n",
       "5   0.8295794789631287     0.25084034344965744   \n",
       "6  0.29660776038825853     0.31471159422776296   \n",
       "7  0.47136354315643714      0.4983164208788222   \n",
       "8  0.48448361443915877      0.2562199197554267   \n",
       "\n",
       "                                       Doc2Vec value  \n",
       "0  [-0.033691 -0.037016 0.029007 0.008522 -0.0166...  \n",
       "1  [-0.028849 -0.061239 -0.010560 0.016685 0.0027...  \n",
       "2  [-0.030819 -0.058584 -0.000901 -0.006251 -0.00...  \n",
       "3  [-0.026400 -0.050600 -0.030745 0.025348 0.0184...  \n",
       "4  [-0.028849 -0.061239 -0.010560 0.016685 0.0027...  \n",
       "5  [-0.031889 -0.025769 0.032461 -0.006925 0.0022...  \n",
       "6  [-0.018071 -0.009378 0.044637 0.006586 -0.0093...  \n",
       "7  [-0.022603 0.006730 0.019023 -0.011535 -0.0062...  \n",
       "8  [-0.004581 -0.021733 0.019696 0.011457 0.00209...  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_hdf(r'C:\\\\Users\\\\Nikolay\\\\Desktop\\\\coll\\\\8-comm_rosbalt_39_79701_output_10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
